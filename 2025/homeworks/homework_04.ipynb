{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUgNFOSlFEzm"
   },
   "source": [
    "# –ò–ê–î\n",
    "\n",
    "## –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 4. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã. \n",
    "\n",
    "### –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "\n",
    "### –û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –∏ —à—Ç—Ä–∞—Ñ—ã\n",
    "\n",
    "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ —Ä–∞–±–æ—Ç—É –±–µ–∑ –±–æ–Ω—É—Å–æ–≤ ‚Äî 10 –±–∞–ª–ª–æ–≤. –°–¥–∞–≤–∞—Ç—å –∑–∞–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Å—Ä–æ–∫–∞ –∂–µ—Å—Ç–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ –Ω–µ–ª—å–∑—è.\n",
    "\n",
    "–°–¥–∞—á–∞ —Ä–∞–±–æ—Ç—ã –ø–æ—Å–ª–µ –º—è–≥–∫–æ–≥–æ –¥–µ–¥–ª–∞–π–Ω–∞ —à—Ç—Ä–∞—Ñ—É–µ—Ç—Å—è —Å—Ç—É–ø–µ–Ω—á–∞—Ç–æ, -1 –±–∞–ª–ª –≤ —Å—É—Ç–∫–∏. –û–¥–∏–Ω —Ä–∞–∑ –∑–∞ –º–æ–¥—É–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç—Å—Ä–æ—á–∫—É –∏ —Å–¥–∞—Ç—å –≤ –∂–µ—Å—Ç–∫–∏–π –¥–µ–¥–ª–∞–π–Ω –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞.\n",
    "\n",
    "–ó–∞–¥–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. ¬´–ü–æ—Ö–æ–∂–∏–µ¬ª —Ä–µ—à–µ–Ω–∏—è —Å—á–∏—Ç–∞—é—Ç—Å—è –ø–ª–∞–≥–∏–∞—Ç–æ–º –∏ –≤—Å–µ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç—ã (–≤ —Ç–æ–º —á–∏—Å–ª–µ —Ç–µ, —É –∫–æ–≥–æ —Å–ø–∏—Å–∞–ª–∏) –Ω–µ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∏—Ç—å –∑–∞ –Ω–µ–≥–æ –±–æ–ª—å—à–µ 0 –±–∞–ª–ª–æ–≤. –ï—Å–ª–∏ –≤—ã –Ω–∞—à–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–∫–æ–≥–æ-—Ç–æ –∏–∑ –∑–∞–¥–∞–Ω–∏–π (–∏–ª–∏ –µ–≥–æ —á–∞—Å—Ç—å) –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —ç—Ç–æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ –≤ –∫–æ–Ω—Ü–µ –≤–∞—à–µ–π —Ä–∞–±–æ—Ç—ã (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤—ã –±—É–¥–µ—Ç–µ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º, –∫—Ç–æ —ç—Ç–æ –Ω–∞—à–µ–ª, –ø–æ—ç—Ç–æ–º—É —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –ø–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –≤ –ø–ª–∞–≥–∏–∞—Ç–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫).\n",
    "\n",
    "–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞ –º–æ–∂–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ –æ—Ç—Ä–∞–∑–∏—Ç—å—Å—è –Ω–∞ –æ—Ü–µ–Ω–∫–µ. –¢–∞–∫–∂–µ –æ—Ü–µ–Ω–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞ –∑–∞ –ø–ª–æ—Ö–æ —á–∏—Ç–∞–µ–º—ã–π –∫–æ–¥ –∏ –ø–ª–æ—Ö–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏. –í—Å–µ –æ—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞—Ç—å—Å—è –∫–æ–¥–æ–º –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –æ —Ç–æ–º, –∫–∞–∫ –æ–Ω–∏ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã.\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–æ–ø—É—Å—Ç–∏–º–æ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö:\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞, –Ω–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏, –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 30%\n",
    "- –£–∫–∞–∑–∞–Ω–∞ –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ–º–ø—Ç\n",
    "- –í –∫–æ–Ω—Ü–µ —Ä–∞–±–æ—Ç—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø–∏—Å–∞—Ç—å —Å–≤–æ–π –æ–ø—ã—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ò–ò –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –¥–∞–Ω–Ω–æ–≥–æ –¥–æ–º–∞—à–Ω–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è. –£–∫–∞–∂–∏—Ç–µ –∫–∞–∫ —á–∞—Å—Ç–æ –í–∞–º –ø—Ä–∏—Ö–æ–¥–∏–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –∫–æ–¥ —Å–≤–æ–∏–º–∏ —Ä—É–∫–∞–º–∏ –∏–ª–∏ –ø—Ä–æ—Å–∏—Ç—å –º–æ–¥–µ–ª—å —á—Ç–æ-—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å. –ë—ã–ª–æ –ª–∏ —ç—Ç–æ –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥ —Å–∞–º–∏–º? \n",
    "\n",
    "–í —Å–ª—É—á–∞–µ –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π —Ä–∞–±–æ—Ç–∞ –Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∏ –æ—Ü–µ–Ω–∫–∞ –∑–∞ –Ω–µ—ë –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 0 –±–∞–ª–ª–æ–≤.\n",
    "\n",
    "### –û –∑–∞–¥–∞–Ω–∏–∏\n",
    "\n",
    "–í —ç—Ç–æ–π –¥–æ–º–∞—à–Ω–µ–π —Ä–∞–±–æ—Ç–µ –≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –∫ BERT'—É –¥–µ–∫–æ–¥–µ—Ä–Ω—É—é —á–∞—Å—Ç—å –∏ —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞–ø–∏—Å–∞–Ω–∏—è tl;dr –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
    "\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ —ç—Ç–æ–º—É –Ω–∞ –æ—Ç–ª–∏—á–Ω—É—é –æ—Ü–µ–Ω–∫—É –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–µ–Ω–µ–µ –∂–∞–¥–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-oW4ttVEL_9"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygnbZcjlgJR9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYW38mH0gKX0"
   },
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (0.5 –±–∞–ª–ª–∞)\n",
    "\n",
    "–ú—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º —Å ü§ó –ò–ª—å–∏ –ì—É—Å–µ–≤–∞ \"gazeta\". –û–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–∞—Ä—ã (–ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ -- –µ–≥–æ —Å–∞–º–º–∞—Ä–∏). \n",
    "\n",
    "–ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –ø—Ä–æ –¥–∞—Ç–∞—Å–µ—Ç –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å [–∑–¥–µ—Å—å](https://huggingface.co/datasets/IlyaGusev/gazeta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDV4tJzzB5Hi"
   },
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–ø–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ datasets\n",
    "# –í—ã –≤–æ–ª—å–Ω—ã –≤–∑—è—Ç—å –º–µ–Ω—å—à–µ –∏–ª–∏ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–æ —á—Ç–æ-—Ç–æ –æ–∫–æ–ª–æ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ–±—ã—á–Ω–æ —Ç–æ–ª—å–∫–æ –Ω–∞ >=10%\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"IlyaGusev/gazeta\", revision=\"v2.0\", split=\"train[:10%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOjri9a4h6K6"
   },
   "source": [
    "–í—ã –¥–æ–ª–∂–Ω—ã –ø–æ–º–Ω–∏—Ç—å, —á—Ç–æ —Ç–µ–∫—Å—Ç—ã –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å**.\n",
    "\n",
    "–î–æ–±–∞–≤—å—Ç–µ –ø–∞–¥–¥–∏–Ω–≥ –¥–æ `max_length=512` –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ —Ç–∞–∫–∂–µ –¥–æ `max_length=128` –¥–ª—è –º–µ—Ç–æ–∫.\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—Ä–µ–∑–∫—É —Ç–µ–∫—Å—Ç–æ–≤, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –≤ —Ç–æ–∫–µ–Ω–∞—Ö –ø—Ä–µ–≤—ã—à–∞–µ—Ç `max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp19tTXfgHsq"
   },
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ Bert\n",
    "\n",
    "model_name = \"deepvk/bert-base-uncased\"  # –£–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ BERT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def preprocess(examples, use_padding=True):\n",
    "\n",
    "    # <YOUR CODE HERE>\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a8e5203a02b845a29f57ca545c50c5d0",
      "09b11d6c6eae4979a1c8cd42e32730ae",
      "911fd70fda12476ab2b788433d6ff83f",
      "bcfc58a3f90745449c3f559aa5ab999a",
      "40c29f2dde174a3c8442d9b86a4e3fe9",
      "ab3d20b0e457431dbe24120bb4becede",
      "68b44cb7bddd4a2f950db1a9c00ce066",
      "2665d63c206a45d88fada74bc984771e",
      "c0ddd3783ec047569c2024e461d5ad0f",
      "06437165ba564bff9e29aa53f4c0df5b",
      "665428d410664f94babcd067b879ce2e"
     ]
    },
    "id": "VQxpZ5ivhjlh",
    "outputId": "b3876676-3dc7-4d1d-894e-f0630172afa4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e5203a02b845a29f57ca545c50c5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess, batched=False)\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmMCjFAqSDWR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = #<YOUR CODE HERE>\n",
    "eval_dataloader = #<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0J1iEfFHxRz"
   },
   "source": [
    "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Decoder-c–µ—Ç–∏ (3 –±–∞–ª–ª–∞)\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞**.\n",
    "\n",
    "–ú–æ–∂–µ—Ç–µ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—Ç—å—Å—è –∫–æ–¥–æ–º —Å —Å–µ–º–∏–Ω–∞—Ä–∞. –í –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ —Å—Ç–æ–∏—Ç (–Ω–æ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –≤—Å–ø–æ–º–Ω–∏—Ç—å –Ω—é–∞–Ω—Å—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5qSblF1EMEV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# –ö–ª–∞—Å—Å –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ BERT —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –¥–µ–∫–æ–¥–µ—Ä–æ–º\n",
    "\n",
    "\n",
    "class BertSummarizer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_model_name=\"bert-base-uncased\",\n",
    "        hidden_size=768,\n",
    "        num_decoder_layers=3,\n",
    "        num_heads=8,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ –≤ –¥–µ–∫–æ–¥–µ—Ä\n",
    "        self.embedding = nn.Embedding(self.bert.config.vocab_size, hidden_size)\n",
    "\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Å–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤–ø–µ—Ä–µ–¥ –≤ –¥–µ–∫–æ–¥–µ—Ä–µ\n",
    "\n",
    "    def generate_square_subsequent_mask(self, T):\n",
    "        # <YOUR CODE HERE>\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, decoder_input_ids):\n",
    "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        memory = (\n",
    "            encoder_outputs.last_hidden_state\n",
    "        )  # –í—ã—Ö–æ–¥—ã BERT –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥–µ–∫–æ–¥–µ—Ä–µ\n",
    "\n",
    "        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–µ–∫–æ–¥–µ—Ä–∞\n",
    "        embedded = self.embedding(decoder_input_ids)\n",
    "\n",
    "        # <YOUR CODE HERE>\n",
    "        output = None  # change this line\n",
    "\n",
    "        return self.softmax(output)\n",
    "\n",
    "    def generate(self, input_ids, attention_mask, tokenizer, max_len=50):\n",
    "        encoder_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        memory = encoder_outputs.last_hidden_state\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        # –ù–∞—á–∏–Ω–∞–µ–º —Å —Ç–æ–∫–µ–Ω–∞ [CLS] –∏–ª–∏ [BOS] (–Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)\n",
    "        decoder_input_ids = torch.full(\n",
    "            (batch_size, 1), tokenizer.cls_token_id, dtype=torch.long\n",
    "        ).to(input_ids.device)\n",
    "        memory = memory.transpose(0, 1)\n",
    "        generated_tokens = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            embedded = self.embedding(decoder_input_ids).transpose(0, 1)\n",
    "\n",
    "            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Å–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤–ø–µ—Ä–µ–¥\n",
    "            decoder_attention_mask = self.generate_square_subsequent_mask(\n",
    "                embedded.size(0)\n",
    "            ).to(input_ids.device)\n",
    "            decoder_output = self.decoder(\n",
    "                tgt=embedded, memory=memory, tgt_mask=decoder_attention_mask\n",
    "            )\n",
    "\n",
    "            output = self.fc_out(decoder_output.transpose(0, 1))\n",
    "\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å —Ç–æ–∫–µ–Ω–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é.\n",
    "            # –ü–æ–º–Ω–∏—Ç–µ, –µ—Å–ª–∏ EOS –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é\n",
    "\n",
    "            # <YOUR CODE HERE>\n",
    "\n",
    "        generated_sequence = tokenizer.decode(\n",
    "            decoder_input_ids.squeeze().tolist(), skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5VXXCKgecHc"
   },
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—à—É –º–æ–¥–µ–ª—å –∏ –ø–æ—Å–º–æ—Ä–∏–º –Ω–∞ –µ–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—Ä—É—Ä—É\n",
    "\n",
    "\n",
    "model = BertSummarizer(bert_model_name=model_name)\n",
    "model = model.to(\"cuda\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "TtvZWsojOh6g",
    "outputId": "6c323397-d141-4169-a3e8-c278b8ddf8fc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'—É–≥–ª–µ ##—Å—Ç–µ—Ä–æ–≤ ##—Ä—è–∑ ##drop –º–Ω–µ–Ω–∏—è –ø—Ä—è–º–æ–∏ ##ru —Ä–∞—Å–ø–∞—Ö —Å–≤—è–∑–∞ –æ–ø–æ–≤–µ ##—Ä–æ–≥–æ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–æ–¥—Å–ª—É —É—Ö–æ–¥–∏–ª–∞ –∫–æ—Ä–æ–±–∫–∞ —Å–º–∞—Ä—Ç —à–ø–∏–æ–Ω ##–æ—Ü–µ–Ω–∏ —Ä–µ–∏—Ç–∏–Ω–≥ —É—á–µ–±–Ω–∏–∫ –ø–æ–¥–æ—à –ø—Ä–æ–∏–¥–µ—Ç üìù –ø—Ä–∞–≤–æ–º –∞–Ω–≥–ª–∏–∏—Å–∫–æ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ body –ø–æ–¥—É–º–∞–ª–∏ —Ä–µ–≥–ª–∞ —à–≤–µ–∏—Ü–∞—Ä ##% ##–∏—Ç—å —à–ø–∏–æ–Ω ##–æ—Ü–µ–Ω–∏ —Ä–µ–∏—Ç–∏–Ω–≥ –ø–æ–º–∏–º–æ club12 ##–æ–ª—å—à–µ ##–≥–∞–Ω—Ç –æ—á–µ—Ä—Ç–∞–Ω–∏—è ##–ª–ª–∏ ##–∑–∞–ª–∏ —Å–æ–±—Ä–∞–≤—à–∏—Ö—Å—è –ø–æ—à—É –≥—Ä—É–ø–ø–æ –º–æ—â–Ω—ã–∏ —Ö–æ—Å—Ç–∏–Ω–≥ —É–¥–∏–≤–ª–µ–Ω–∏–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–∏ œÖ'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "eval_data_sample = next(iter(eval_dataloader))\n",
    "model.generate(\n",
    "    eval_data_sample[\"input_ids\"][:1].to(\"cuda\"),\n",
    "    eval_data_sample[\"attention_mask\"][:1].to(\"cuda\"),\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H2L-0BmZyu1"
   },
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (1 –±–∞–ª–ª)\n",
    "\n",
    "0.25 –±–∞–ª–ª–∞ –∑–∞ –ø—Ä–æ—Å—Ç–µ–π—à–∏–π —Ä–∞–±–æ—á–∏–π —Ü–∏–∫–ª; \n",
    "\n",
    "0.5 –±–∞–ª–ª–∞ –∑–∞ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –ª–æ—Å—Å–∞ –∏ –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç—Ä–µ–π–Ω–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.\n",
    "\n",
    "0.25 –±–∞–ª–ª–∞ –∑–∞ –ª–æ–≥–≥–∏–Ω–≥ –≤ —Ç–µ–Ω–∑–æ—Ä–±–æ—Ä–¥ –∏–ª–∏ WandB\n",
    "\n",
    "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ü–∏–∫–ª –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us3xiacHBm-U"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏\n",
    "# –í—Å–µ –ø–æ–º–Ω—è—Ç, —á—Ç–æ –Ω–∞–¥–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω?\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    model, input_ids, attention_mask, decoder_input_ids, optimizer, criterion\n",
    "):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids, attention_mask, decoder_input_ids)\n",
    "    loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_input_ids.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo01OhsoaacU"
   },
   "source": [
    "## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (1 –±–∞–ª–ª)\n",
    "\n",
    "–ü–æ 0.33 –±–∞–ª–ª–∞ –∑–∞ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –∏–∑ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã—Ö –º–µ—Ç—Ä–∏–∫\n",
    "\n",
    "**–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫–∏—Ü–∏—é –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.**\n",
    "\n",
    "–ß—Ç–æ –º—ã —Ö–æ—Ç–∏–º —Å—á–∏—Ç–∞—Ç—å:\n",
    " 1. [HuggingFace Rouge](https://huggingface.co/spaces/evaluate-metric/rouge)\n",
    " 2. [HuggingFace Bleu](https://huggingface.co/spaces/evaluate-metric/bleu)\n",
    " 3. [HuggingFace BERT Score](https://huggingface.co/spaces/evaluate-metric/bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBNcGXt8aSJ2"
   },
   "outputs": [],
   "source": [
    "def compute_metrics():\n",
    "    # <YOUR CODE HERE>\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluation():\n",
    "    # <YOUR CODE HERE>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ5GaAZ1chBu"
   },
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (0.5 –±–∞–ª–ª–∞)\n",
    "**–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å, —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ª—É—á—à—É—é –≤–µ—Ä—Å–∏—é** (–º–µ—Ç–æ–¥ `.save_pretrained()` –æ–±—ä–µ–∫—Ç–∞ –∫–ª–∞—Å—Å–∞ AutoModel... –∏–ª–∏ `torch.save()`) **–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**. –£—á—Ç–∏—Ç–µ, —á—Ç–æ –µ—Å–ª–∏ –∏–∑–º–µ–Ω—è–ª—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–∞ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é), –µ–≥–æ —Ç–æ–∂–µ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.\n",
    "\n",
    "–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å ruT5-small –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –ú—ã –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –¥–∞–µ–º –±–µ–π–∑–ª–∞–π–Ω –∏–º–µ–Ω–Ω–æ –≤ —Ç–∞–∫–æ–º –≤–∏–¥–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHu9RzbQcceV"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"YOUR MODEL\")\n",
    "summary = #<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbQH_vj6d2Ue"
   },
   "source": [
    "## –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–µ –∂–∞–¥–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ (4 –±–∞–ª–ª–∞)\n",
    "–í—Å–µ–≥–¥–∞ –ª–∏ –≤—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ ‚Äì¬†—ç—Ç–æ –ª—É—á—à–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞?\n",
    "\n",
    "<details>\n",
    "    <summary>–°–ø–æ–π–ª–µ—Ä</summary>\n",
    "    <p>–ù–µ—Ç</p>\n",
    "</details>\n",
    "\n",
    "**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:**\n",
    "\n",
    "| Strategy | Description | Pros & Cons |\n",
    "| --- | --- | --- |\n",
    "| Greedy Search | Chooses the word with the highest probability as the next word in the sequence. | **Pros:** Simple and fast. <br><br/> **Cons:** Can lead to repetitive and incoherent text. |\n",
    "| Sampling with Temperature | Introduces randomness in the word selection. A higher temperature leads to more randomness. | **Pros:** Allows exploration and diverse output. <br><br/> **Cons:** Higher temperatures can lead to nonsensical outputs. |\n",
    "| Nucleus Sampling (Top-p Sampling) | Selects the next word from a truncated vocabulary, the \"nucleus\" of words <br/> that have a cumulative probability exceeding a pre-specified threshold (p). | **Pros:** Balances diversity and quality. <br><br/> **Cons:** Setting an optimal 'p' can be tricky. |\n",
    "| Beam Search | Explores multiple hypotheses (sequences of words) at each step, and keeps <br/> the 'k' most likely, where 'k' is the beam width. | **Pros:** Produces more reliable results than greedy search. <br><br/> **Cons:** Can lack diversity and lead to generic responses. |\n",
    "| Top-k Sampling | Randomly selects the next word from the top 'k' words with the highest probabilities. | **Pros:** Introduces randomness, increasing output diversity. <br><br/> **Cons:** Random selection can sometimes lead to less coherent outputs. |\n",
    "| Length Normalization | Prevents the model from favoring shorter sequences by dividing the log probabilities <br/> by the sequence length raised to some power. | **Pros:** Makes longer and potentially more informative sequences more likely. <br><br/> **Cons:** Tuning the normalization factor can be difficult. |\n",
    "| Stochastic Beam Search | Introduces randomness into the selection process of the 'k' hypotheses in beam search. | **Pros:** Increases diversity in the generated text. <br><br/> **Cons:** The trade-off between diversity and quality can be tricky to manage. |\n",
    "| Decoding with Minimum Bayes Risk (MBR) | Chooses the hypothesis (out of many) that minimizes expected loss under a loss function. | **Pros:** Optimizes the output according to a specific loss function. <br><br/> **Cons:** Computationally more complex and requires a good loss function. |\n",
    "\n",
    "–°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ—Ç–∞—Ü–∏—é:\n",
    "- [reference for `AutoModelForCausalLM.generate()`](https://huggingface.co/docs/transformers/v4.29.1/en/main_classes/text_generation#transformers.GenerationMixin.generate)\n",
    "- [reference for `AutoTokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)\n",
    "- Huggingface [docs on generation strategies](https://huggingface.co/docs/transformers/generation_strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQF4Vc3msKpF"
   },
   "source": [
    "**1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Top-k –≤ –º–µ—Ç–æ–¥–µ `generate`** (1 –±–∞–ª–ª).   \n",
    "\n",
    "**2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Nucleus Sampling (Top-p) –≤ –º–µ—Ç–æ–¥–µ `generate`** (1 –±–∞–ª–ª)\n",
    "\n",
    "**3. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é Beam Search** (2 –±–∞–ª–ª–∞)\n",
    "\n",
    "–ü–æ–ª—É—á–∏–ª–æ—Å—å –ª–∏ —É–ª—É—á—à–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRfAEfP5kHcc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbiksVMOOvO8"
   },
   "source": [
    "## –ë–æ–Ω—É—Å (1 –±–∞–ª–ª)\n",
    "\n",
    "–ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å:\n",
    "\n",
    "- –æ—Ç –∏–º–µ—é—â–µ–π—Å—è –º–æ–¥–µ–ª–∏ \"–æ—Ç–∫—É—Å–∏—Ç—å\" —Ç–æ–ª—å–∫–æ –¥–µ–∫–æ–¥–µ—Ä–Ω—É—é —á–∞—Å—Ç—å\n",
    "- –Ω–∞–ø–∏—Å–∞—Ç—å —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è (—Å–∫–æ—Ä–µ–µ –ø–æ–ø—Ä–∞–≤–∏—Ç—å –∏–º–µ—é—â–∏–π—Å—è) –∏ –¥–æ–æ–±—É—á–∏—Ç—å –¥–µ–∫–æ–¥–µ—Ä\n",
    "- –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –∏ \"–≥–ª–∞–∑–∞–º–∏\"\n",
    "- –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å \"–î–∞–µ—Ç –ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Encoder-Decoder –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –±—É—Å—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏?\" —Å –ø—Ä—É—Ñ–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZM1xLliO1QM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06437165ba564bff9e29aa53f4c0df5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09b11d6c6eae4979a1c8cd42e32730ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab3d20b0e457431dbe24120bb4becede",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_68b44cb7bddd4a2f950db1a9c00ce066",
      "value": "Map:‚Äá100%"
     }
    },
    "2665d63c206a45d88fada74bc984771e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c29f2dde174a3c8442d9b86a4e3fe9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "665428d410664f94babcd067b879ce2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68b44cb7bddd4a2f950db1a9c00ce066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "911fd70fda12476ab2b788433d6ff83f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2665d63c206a45d88fada74bc984771e",
      "max": 3048,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0ddd3783ec047569c2024e461d5ad0f",
      "value": 3048
     }
    },
    "a8e5203a02b845a29f57ca545c50c5d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09b11d6c6eae4979a1c8cd42e32730ae",
       "IPY_MODEL_911fd70fda12476ab2b788433d6ff83f",
       "IPY_MODEL_bcfc58a3f90745449c3f559aa5ab999a"
      ],
      "layout": "IPY_MODEL_40c29f2dde174a3c8442d9b86a4e3fe9"
     }
    },
    "ab3d20b0e457431dbe24120bb4becede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcfc58a3f90745449c3f559aa5ab999a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06437165ba564bff9e29aa53f4c0df5b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_665428d410664f94babcd067b879ce2e",
      "value": "‚Äá3048/3048‚Äá[00:13&lt;00:00,‚Äá206.31‚Äáexamples/s]"
     }
    },
    "c0ddd3783ec047569c2024e461d5ad0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
