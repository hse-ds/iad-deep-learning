{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_upCOEI3Upu"
      },
      "source": [
        "# Основы глубинного обучения, майнор ИАД\n",
        "\n",
        "## Домашнее задание 1: полносвязные сети\n",
        "\n",
        "**ФИО:**\n",
        "\n",
        "**Факт о себе:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Общая информация\n",
        "\n",
        "__Дата выдачи:__ 22.09.2025\n",
        "\n",
        "__Мягкий дедлайн:__ 23:59MSK 12.10.2025\n",
        "\n",
        "__Жесткий дедлайн:__ 23:59MSK 19.10.2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).  Если два студента сгенерировали в нейронке одинаковые либо похожие решения, это считается плагиатом и приводит к обнулению обеих работ.\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "Итогова оценка считается как\n",
        "\n",
        "$$\n",
        "min(part_1, part_2) \\cdot 0.6 + max(part_1, part_2) \\cdot 0.2 + part_3 \\cdot 0.2\n",
        "$$\n",
        "\n",
        "где $part_1$, $part_2$ и $part_3$ - оценки за первую, вторую и третью части работы\n",
        "\n",
        "> Также, за домашнее задание выставляется 0, если не сделано нулевое задание либо нет подробного описания ваших экспериментов в третьей части."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Оформление\n",
        "\n",
        "1. Обязательно фиксируйте зерно генератора случайных чисел в экспериментах. При перезапуске кода значения не должны меняться.\n",
        "2. Вверху файла подпишите фамилию, имя и какой-то занимательный факт о себе.\n",
        "3. Обратите внимание, что у графиков должны быть подписаны оси, заголовок графика и при необходимости обязательно наличие легенды. \n",
        "\n",
        "> За отсутствие названий графиков и подписей к осям могут снижаться баллы. Все картинки должны быть самодостаточны и визуально удобны для восприятия, так чтобы не нужно было смотреть ваш код или знать задание, чтобы понять что на них изображено.\n",
        "\n",
        "Из каждого проведённого эксперимента делайте выводы и фиксируйте их в третьем зааднии. Эти выводы не должны быть поверхностными и очевидными. Не будьте мудрым королём.\n",
        "\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/hse-ds/iad-deep-learning/refs/heads/master/2025/homeworks/king.png\" width=\"300\"> \n",
        "</center>\n",
        "\n",
        "**Пример плохого вывода:** Синенькая линия идет вверх, а красная вниз. Черненькая идет вниз, а потом вверх. \n",
        "\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/hse-ds/iad-deep-learning/refs/heads/master/2025/homeworks/bad_lines.png\" width=\"600\"> \n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## О задании\n",
        "\n",
        "Ввам предстоит обучить полносвязную нейронную сеть для предсказания года выпуска песни по ее аудио-признакам. Для этого мы будем использовать [Million Songs Dataset](https://samyzaf.com/ML/song_year/song_year.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RI_eoe063VaP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Начнем с того, что скачаем и загрузим данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NgSZeU-7vgj",
        "outputId": "4d53550a-d654-4efd-ddc8-e580328bab80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-09-20 18:34:11--  https://archive.ics.uci.edu/static/public/203/yearpredictionmsd.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘yearpredictionmsd.zip’\n",
            "\n",
            "yearpredictionmsd.z     [             <=>    ] 201,24M  5,81MB/s    in 84s     \n",
            "\n",
            "2025-09-20 18:35:36 (2,41 MB/s) - ‘yearpredictionmsd.zip’ saved [211011981]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O yearpredictionmsd.zip https://archive.ics.uci.edu/static/public/203/yearpredictionmsd.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "DSVJZzkJ7zZE",
        "outputId": "2c5b9ac3-1194-4c3e-be92-067640e01e3a",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0         1         2         3         4         5         6         7   \\\n",
              "0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n",
              "1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
              "2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
              "3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
              "4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
              "\n",
              "         8         9   ...        81         82        83        84        85  \\\n",
              "0 -12.23257   7.83089  ...  13.01620  -54.40548  58.99367  15.37344   1.11144   \n",
              "1  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n",
              "2  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n",
              "3 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n",
              "4  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n",
              "\n",
              "         86         87        88         89        90  \n",
              "0 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
              "1 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
              "2  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
              "3  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
              "4  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
              "\n",
              "[5 rows x 91 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('yearpredictionmsd.zip', header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим на статистики по данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1998.397082</td>\n",
              "      <td>43.387126</td>\n",
              "      <td>1.289554</td>\n",
              "      <td>8.658347</td>\n",
              "      <td>1.164124</td>\n",
              "      <td>-6.553601</td>\n",
              "      <td>-9.521975</td>\n",
              "      <td>-2.391089</td>\n",
              "      <td>-1.793236</td>\n",
              "      <td>3.727876</td>\n",
              "      <td>...</td>\n",
              "      <td>15.755406</td>\n",
              "      <td>-73.461500</td>\n",
              "      <td>41.542422</td>\n",
              "      <td>37.934119</td>\n",
              "      <td>0.315751</td>\n",
              "      <td>17.669213</td>\n",
              "      <td>-26.315336</td>\n",
              "      <td>4.458641</td>\n",
              "      <td>20.035136</td>\n",
              "      <td>1.329105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.931046</td>\n",
              "      <td>6.067558</td>\n",
              "      <td>51.580351</td>\n",
              "      <td>35.268585</td>\n",
              "      <td>16.322790</td>\n",
              "      <td>22.860785</td>\n",
              "      <td>12.857751</td>\n",
              "      <td>14.571873</td>\n",
              "      <td>7.963827</td>\n",
              "      <td>10.582861</td>\n",
              "      <td>...</td>\n",
              "      <td>32.099635</td>\n",
              "      <td>175.618889</td>\n",
              "      <td>122.228799</td>\n",
              "      <td>95.050631</td>\n",
              "      <td>16.161764</td>\n",
              "      <td>114.427905</td>\n",
              "      <td>173.977336</td>\n",
              "      <td>13.346557</td>\n",
              "      <td>185.558247</td>\n",
              "      <td>22.088576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1922.000000</td>\n",
              "      <td>1.749000</td>\n",
              "      <td>-337.092500</td>\n",
              "      <td>-301.005060</td>\n",
              "      <td>-154.183580</td>\n",
              "      <td>-181.953370</td>\n",
              "      <td>-81.794290</td>\n",
              "      <td>-188.214000</td>\n",
              "      <td>-72.503850</td>\n",
              "      <td>-126.479040</td>\n",
              "      <td>...</td>\n",
              "      <td>-437.722030</td>\n",
              "      <td>-4402.376440</td>\n",
              "      <td>-1810.689190</td>\n",
              "      <td>-3098.350310</td>\n",
              "      <td>-341.789120</td>\n",
              "      <td>-3168.924570</td>\n",
              "      <td>-4319.992320</td>\n",
              "      <td>-236.039260</td>\n",
              "      <td>-7458.378150</td>\n",
              "      <td>-381.424430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1994.000000</td>\n",
              "      <td>39.954690</td>\n",
              "      <td>-26.059520</td>\n",
              "      <td>-11.462710</td>\n",
              "      <td>-8.487500</td>\n",
              "      <td>-20.666450</td>\n",
              "      <td>-18.440990</td>\n",
              "      <td>-10.780600</td>\n",
              "      <td>-6.468420</td>\n",
              "      <td>-2.293660</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.812650</td>\n",
              "      <td>-139.555160</td>\n",
              "      <td>-20.986900</td>\n",
              "      <td>-4.669540</td>\n",
              "      <td>-6.781590</td>\n",
              "      <td>-31.580610</td>\n",
              "      <td>-101.530300</td>\n",
              "      <td>-2.566090</td>\n",
              "      <td>-59.509270</td>\n",
              "      <td>-8.820210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2002.000000</td>\n",
              "      <td>44.258500</td>\n",
              "      <td>8.417850</td>\n",
              "      <td>10.476320</td>\n",
              "      <td>-0.652840</td>\n",
              "      <td>-6.007770</td>\n",
              "      <td>-11.188390</td>\n",
              "      <td>-2.046670</td>\n",
              "      <td>-1.736450</td>\n",
              "      <td>3.822310</td>\n",
              "      <td>...</td>\n",
              "      <td>9.171850</td>\n",
              "      <td>-53.090060</td>\n",
              "      <td>28.791060</td>\n",
              "      <td>33.623630</td>\n",
              "      <td>0.820840</td>\n",
              "      <td>15.598470</td>\n",
              "      <td>-21.204120</td>\n",
              "      <td>3.117640</td>\n",
              "      <td>7.759730</td>\n",
              "      <td>0.053050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2006.000000</td>\n",
              "      <td>47.833890</td>\n",
              "      <td>36.124010</td>\n",
              "      <td>29.764820</td>\n",
              "      <td>8.787540</td>\n",
              "      <td>7.741870</td>\n",
              "      <td>-2.388960</td>\n",
              "      <td>6.508580</td>\n",
              "      <td>2.913450</td>\n",
              "      <td>9.961820</td>\n",
              "      <td>...</td>\n",
              "      <td>26.274480</td>\n",
              "      <td>13.478730</td>\n",
              "      <td>89.661770</td>\n",
              "      <td>77.785800</td>\n",
              "      <td>8.470990</td>\n",
              "      <td>67.794960</td>\n",
              "      <td>52.389330</td>\n",
              "      <td>9.967740</td>\n",
              "      <td>86.351610</td>\n",
              "      <td>9.679520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2011.000000</td>\n",
              "      <td>61.970140</td>\n",
              "      <td>384.065730</td>\n",
              "      <td>322.851430</td>\n",
              "      <td>335.771820</td>\n",
              "      <td>262.068870</td>\n",
              "      <td>166.236890</td>\n",
              "      <td>172.402680</td>\n",
              "      <td>126.741270</td>\n",
              "      <td>146.297950</td>\n",
              "      <td>...</td>\n",
              "      <td>840.973380</td>\n",
              "      <td>4469.454870</td>\n",
              "      <td>3210.701700</td>\n",
              "      <td>1734.079690</td>\n",
              "      <td>260.544900</td>\n",
              "      <td>3662.065650</td>\n",
              "      <td>2833.608950</td>\n",
              "      <td>463.419500</td>\n",
              "      <td>7393.398440</td>\n",
              "      <td>677.899630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0              1              2              3   \\\n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000   \n",
              "mean     1998.397082      43.387126       1.289554       8.658347   \n",
              "std        10.931046       6.067558      51.580351      35.268585   \n",
              "min      1922.000000       1.749000    -337.092500    -301.005060   \n",
              "25%      1994.000000      39.954690     -26.059520     -11.462710   \n",
              "50%      2002.000000      44.258500       8.417850      10.476320   \n",
              "75%      2006.000000      47.833890      36.124010      29.764820   \n",
              "max      2011.000000      61.970140     384.065730     322.851430   \n",
              "\n",
              "                  4              5              6              7   \\\n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000   \n",
              "mean        1.164124      -6.553601      -9.521975      -2.391089   \n",
              "std        16.322790      22.860785      12.857751      14.571873   \n",
              "min      -154.183580    -181.953370     -81.794290    -188.214000   \n",
              "25%        -8.487500     -20.666450     -18.440990     -10.780600   \n",
              "50%        -0.652840      -6.007770     -11.188390      -2.046670   \n",
              "75%         8.787540       7.741870      -2.388960       6.508580   \n",
              "max       335.771820     262.068870     166.236890     172.402680   \n",
              "\n",
              "                  8              9   ...             81             82  \\\n",
              "count  515345.000000  515345.000000  ...  515345.000000  515345.000000   \n",
              "mean       -1.793236       3.727876  ...      15.755406     -73.461500   \n",
              "std         7.963827      10.582861  ...      32.099635     175.618889   \n",
              "min       -72.503850    -126.479040  ...    -437.722030   -4402.376440   \n",
              "25%        -6.468420      -2.293660  ...      -1.812650    -139.555160   \n",
              "50%        -1.736450       3.822310  ...       9.171850     -53.090060   \n",
              "75%         2.913450       9.961820  ...      26.274480      13.478730   \n",
              "max       126.741270     146.297950  ...     840.973380    4469.454870   \n",
              "\n",
              "                  83             84             85             86  \\\n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000   \n",
              "mean       41.542422      37.934119       0.315751      17.669213   \n",
              "std       122.228799      95.050631      16.161764     114.427905   \n",
              "min     -1810.689190   -3098.350310    -341.789120   -3168.924570   \n",
              "25%       -20.986900      -4.669540      -6.781590     -31.580610   \n",
              "50%        28.791060      33.623630       0.820840      15.598470   \n",
              "75%        89.661770      77.785800       8.470990      67.794960   \n",
              "max      3210.701700    1734.079690     260.544900    3662.065650   \n",
              "\n",
              "                  87             88             89             90  \n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000  \n",
              "mean      -26.315336       4.458641      20.035136       1.329105  \n",
              "std       173.977336      13.346557     185.558247      22.088576  \n",
              "min     -4319.992320    -236.039260   -7458.378150    -381.424430  \n",
              "25%      -101.530300      -2.566090     -59.509270      -8.820210  \n",
              "50%       -21.204120       3.117640       7.759730       0.053050  \n",
              "75%        52.389330       9.967740      86.351610       9.679520  \n",
              "max      2833.608950     463.419500    7393.398440     677.899630  \n",
              "\n",
              "[8 rows x 91 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Целевая переменная, год выпуска песни, записана в первом столбце. Посмотрим на ее распределение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAGwCAYAAACAZ5AeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2AElEQVR4nO3de1xVdb7/8TeoXLxsyAvgHlFp9HhJRvMSYuXUyBGLOofRSo1TjpGWgaVUXiZFm7GhbMxLmUzNKeox+sicGc3UKMZrKaGSjkJKVt4a22AHYScmIKzfH/1Y4x5wRPwioK/n47Efj/b6fvZ3fdb+Frxbe+2Fl2VZlgAAAHBZvBu6AQAAgKsBoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAY0LyhG7iWVFZW6sSJE2rTpo28vLwauh0AAFALlmXp+++/l9PplLf3hc9HEaquoBMnTig0NLSh2wAAAHVw/PhxderU6YLjhKorqE2bNpJ+XBSHw9HA3QAAgNpwu90KDQ21f49fCKHqCqr6yM/hcBCqAABoYi526Q4XqgMAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABjRv6AYAAEDj03XG+nqb+8jzMfU2d0PiTBUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABjQoKFq27Ztuvvuu+V0OuXl5aU1a9bYY+Xl5Zo+fbrCw8PVqlUrOZ1OPfjggzpx4oTHHIWFhYqLi5PD4VBgYKDi4+N1+vRpj5p9+/bp1ltvlZ+fn0JDQzV//vxqvaxatUo9e/aUn5+fwsPDtWHDBo9xy7KUnJysjh07yt/fX1FRUTp06JC5NwMAADRpDRqqSkpK1LdvXy1durTa2JkzZ/TZZ59p9uzZ+uyzz/TXv/5VeXl5+q//+i+Puri4OOXm5iojI0Pr1q3Ttm3bNHHiRHvc7XZr+PDh6tKli7Kzs/Xiiy9q7ty5eu211+yaHTt2aOzYsYqPj9eePXsUGxur2NhY5eTk2DXz58/XkiVLlJqaqqysLLVq1UrR0dE6e/ZsPbwzAACgqfGyLMtq6CYkycvLS6tXr1ZsbOwFa3bt2qWbbrpJR48eVefOnXXgwAH17t1bu3bt0sCBAyVJ6enpuvPOO/XNN9/I6XRq2bJleuaZZ+RyueTj4yNJmjFjhtasWaODBw9KkkaPHq2SkhKtW7fO3tfgwYPVr18/paamyrIsOZ1OPfnkk3rqqackScXFxQoODlZaWprGjBlTY7+lpaUqLS21n7vdboWGhqq4uFgOh+Oy3i8AAOpT1xnr623uI8/H1Nvc9cHtdisgIOCiv7+b1DVVxcXF8vLyUmBgoCQpMzNTgYGBdqCSpKioKHl7eysrK8uuGTp0qB2oJCk6Olp5eXk6deqUXRMVFeWxr+joaGVmZkqSDh8+LJfL5VETEBCgiIgIu6YmKSkpCggIsB+hoaGX9wYAAIBGq8mEqrNnz2r69OkaO3asnRJdLpeCgoI86po3b662bdvK5XLZNcHBwR41Vc8vVnP++Pmvq6mmJjNnzlRxcbH9OH78+CUdMwAAaDqaN3QDtVFeXq777rtPlmVp2bJlDd1Orfn6+srX17eh2wAAAFdAoz9TVRWojh49qoyMDI/PMkNCQlRQUOBRf+7cORUWFiokJMSuyc/P96ipen6xmvPHz39dTTUAAODa1qhDVVWgOnTokP72t7+pXbt2HuORkZEqKipSdna2vW3Tpk2qrKxURESEXbNt2zaVl5fbNRkZGerRo4euu+46u2bjxo0ec2dkZCgyMlKSFBYWppCQEI8at9utrKwsuwYAAFzbGjRUnT59Wnv37tXevXsl/XhB+N69e3Xs2DGVl5frnnvu0e7du7V8+XJVVFTI5XLJ5XKprKxMktSrVy+NGDFCEyZM0M6dO7V9+3YlJiZqzJgxcjqdkqT7779fPj4+io+PV25urlauXKnFixcrKSnJ7uOJJ55Qenq6FixYoIMHD2ru3LnavXu3EhMTJf34zcQpU6Zo3rx5Wrt2rfbv368HH3xQTqfz335bEQAAXDsa9JYKW7Zs0e23315t+7hx4zR37lyFhYXV+LrNmzfrtttuk/TjzT8TExP1/vvvy9vbW6NGjdKSJUvUunVru37fvn1KSEjQrl271L59e02ePFnTp0/3mHPVqlWaNWuWjhw5ou7du2v+/Pm688477XHLsjRnzhy99tprKioq0i233KJXX31V//Ef/1Hr463tVzIBAGho3FLhn2r7+7vR3KfqWkCoAgA0FYSqf7oq71MFAADQWBGqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAFN4g8qAwCAq0d93QOroe9/xZkqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAxo0FC1bds23X333XI6nfLy8tKaNWs8xi3LUnJysjp27Ch/f39FRUXp0KFDHjWFhYWKi4uTw+FQYGCg4uPjdfr0aY+affv26dZbb5Wfn59CQ0M1f/78ar2sWrVKPXv2lJ+fn8LDw7Vhw4ZL7gUAAFy7GjRUlZSUqG/fvlq6dGmN4/Pnz9eSJUuUmpqqrKwstWrVStHR0Tp79qxdExcXp9zcXGVkZGjdunXatm2bJk6caI+73W4NHz5cXbp0UXZ2tl588UXNnTtXr732ml2zY8cOjR07VvHx8dqzZ49iY2MVGxurnJycS+oFAABcu7wsy7IauglJ8vLy0urVqxUbGyvpxzNDTqdTTz75pJ566ilJUnFxsYKDg5WWlqYxY8bowIED6t27t3bt2qWBAwdKktLT03XnnXfqm2++kdPp1LJly/TMM8/I5XLJx8dHkjRjxgytWbNGBw8elCSNHj1aJSUlWrdund3P4MGD1a9fP6Wmptaql9pwu90KCAhQcXGxHA6HkfcNAID60HXG+oZu4ZIdeT6mXuat7e/vRntN1eHDh+VyuRQVFWVvCwgIUEREhDIzMyVJmZmZCgwMtAOVJEVFRcnb21tZWVl2zdChQ+1AJUnR0dHKy8vTqVOn7Jrz91NVU7Wf2vRSk9LSUrndbo8HAAC4OjXaUOVyuSRJwcHBHtuDg4PtMZfLpaCgII/x5s2bq23bth41Nc1x/j4uVHP++MV6qUlKSooCAgLsR2ho6EWOGgAANFWNNlRdDWbOnKni4mL7cfz48YZuCQAA1JNGG6pCQkIkSfn5+R7b8/Pz7bGQkBAVFBR4jJ87d06FhYUeNTXNcf4+LlRz/vjFeqmJr6+vHA6HxwMAAFydGm2oCgsLU0hIiDZu3Ghvc7vdysrKUmRkpCQpMjJSRUVFys7Otms2bdqkyspKRURE2DXbtm1TeXm5XZORkaEePXrouuuus2vO309VTdV+atMLAAC4tjVvyJ2fPn1aX375pf388OHD2rt3r9q2bavOnTtrypQpmjdvnrp3766wsDDNnj1bTqfT/oZgr169NGLECE2YMEGpqakqLy9XYmKixowZI6fTKUm6//779eyzzyo+Pl7Tp09XTk6OFi9erIULF9r7feKJJ/Tzn/9cCxYsUExMjN555x3t3r3bvu2Cl5fXRXsBAKAhNMVv6V2tGjRU7d69W7fffrv9PCkpSZI0btw4paWladq0aSopKdHEiRNVVFSkW265Renp6fLz87Nfs3z5ciUmJmrYsGHy9vbWqFGjtGTJEns8ICBAH330kRISEjRgwAC1b99eycnJHveyGjJkiFasWKFZs2bp17/+tbp37641a9aoT58+dk1tegEAANeuRnOfqmsB96kCAJjGmap/4j5VAAAAVwFCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABjTqUFVRUaHZs2crLCxM/v7++ulPf6rf/va3sizLrrEsS8nJyerYsaP8/f0VFRWlQ4cOecxTWFiouLg4ORwOBQYGKj4+XqdPn/ao2bdvn2699Vb5+fkpNDRU8+fPr9bPqlWr1LNnT/n5+Sk8PFwbNmyonwMHAABNTqMOVS+88IKWLVumV155RQcOHNALL7yg+fPn6+WXX7Zr5s+fryVLlig1NVVZWVlq1aqVoqOjdfbsWbsmLi5Oubm5ysjI0Lp167Rt2zZNnDjRHne73Ro+fLi6dOmi7Oxsvfjii5o7d65ee+01u2bHjh0aO3as4uPjtWfPHsXGxio2NlY5OTlX5s0AAACNmpd1/mmfRuauu+5ScHCw/vd//9feNmrUKPn7++tPf/qTLMuS0+nUk08+qaeeekqSVFxcrODgYKWlpWnMmDE6cOCAevfurV27dmngwIGSpPT0dN1555365ptv5HQ6tWzZMj3zzDNyuVzy8fGRJM2YMUNr1qzRwYMHJUmjR49WSUmJ1q1bZ/cyePBg9evXT6mpqTX2X1paqtLSUvu52+1WaGioiouL5XA4zL5ZAIBrUtcZ6xu6hUbjyPMx9TKv2+1WQEDARX9/N+ozVUOGDNHGjRv1xRdfSJL+/ve/65NPPtEdd9whSTp8+LBcLpeioqLs1wQEBCgiIkKZmZmSpMzMTAUGBtqBSpKioqLk7e2trKwsu2bo0KF2oJKk6Oho5eXl6dSpU3bN+fupqqnaT01SUlIUEBBgP0JDQy/n7QAAAI1Y84Zu4N+ZMWOG3G63evbsqWbNmqmiokLPPfec4uLiJEkul0uSFBwc7PG64OBge8zlcikoKMhjvHnz5mrbtq1HTVhYWLU5qsauu+46uVyuf7ufmsycOVNJSUn286ozVQAA4OrTqEPVu+++q+XLl2vFihW64YYbtHfvXk2ZMkVOp1Pjxo1r6PYuytfXV76+vg3dBgAAuAIadah6+umnNWPGDI0ZM0aSFB4erqNHjyolJUXjxo1TSEiIJCk/P18dO3a0X5efn69+/fpJkkJCQlRQUOAx77lz51RYWGi/PiQkRPn5+R41Vc8vVlM1DgAArm2N+pqqM2fOyNvbs8VmzZqpsrJSkhQWFqaQkBBt3LjRHne73crKylJkZKQkKTIyUkVFRcrOzrZrNm3apMrKSkVERNg127ZtU3l5uV2TkZGhHj166LrrrrNrzt9PVU3VfgAAwLWtUYequ+++W88995zWr1+vI0eOaPXq1XrppZf0y1/+UpLk5eWlKVOmaN68eVq7dq3279+vBx98UE6nU7GxsZKkXr16acSIEZowYYJ27typ7du3KzExUWPGjJHT6ZQk3X///fLx8VF8fLxyc3O1cuVKLV682ON6qCeeeELp6elasGCBDh48qLlz52r37t1KTEy84u8LAABofBr1x38vv/yyZs+erccee0wFBQVyOp165JFHlJycbNdMmzZNJSUlmjhxooqKinTLLbcoPT1dfn5+ds3y5cuVmJioYcOGydvbW6NGjdKSJUvs8YCAAH300UdKSEjQgAED1L59eyUnJ3vcy2rIkCFasWKFZs2apV//+tfq3r271qxZoz59+lyZNwMAADRqjfo+VVeb2t7nAgCA2uI+Vf/EfaoAAACuAoQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwIA6hapf/OIXKioqqrbd7XbrF7/4xeX2BAAA0OTUKVRt2bJFZWVl1bafPXtWH3/88WU3BQAA0NRc0t/+27dvn/3Pn3/+uVwul/28oqJC6enp+slPfmKuOwAAgCbikkJVv3795OXlJS8vrxo/5vP399fLL79srDkAAICm4pJC1eHDh2VZlq6//nrt3LlTHTp0sMd8fHwUFBSkZs2aGW8SAACgsbukUNWlSxdJUmVlZb00AwAA0FRdUqg636FDh7R582YVFBRUC1nJycmX3RgAAEBTUqdQ9frrr2vSpElq3769QkJC5OXlZY95eXkRqgAAwDWnTqFq3rx5eu655zR9+nTT/QAAADRJdbpP1alTp3Tvvfea7gUAAKDJqlOouvfee/XRRx+Z7gUAAKDJqtPHf926ddPs2bP16aefKjw8XC1atPAYf/zxx400BwAA0FR4WZZlXeqLwsLCLjyhl5e+/vrry2rqauV2uxUQEKDi4mI5HI6GbgcAcBXoOmN9Q7fQaBx5PqZe5q3t7+86nak6fPhwnRsDAAC4GtXpmioAAAB4qtOZqoceeujfjr/xxht1agYAAKCpqlOoOnXqlMfz8vJy5eTkqKioqMY/tAwAAHC1q1OoWr16dbVtlZWVmjRpkn76059edlMAAABNjbFrqry9vZWUlKSFCxeamhIAAKDJMHqh+ldffaVz586ZnBIAAKBJqNPHf0lJSR7PLcvSt99+q/Xr12vcuHFGGgMAAGhK6hSq9uzZ4/Hc29tbHTp00IIFCy76zUAAAICrUZ1C1ebNm033AQAA0KTVKVRVOXnypPLy8iRJPXr0UIcOHYw0BQAA0NTU6UL1kpISPfTQQ+rYsaOGDh2qoUOHyul0Kj4+XmfOnDHdIwAAQKNXp1CVlJSkrVu36v3331dRUZGKior03nvvaevWrXryySdN9wgAANDo1enjv7/85S/685//rNtuu83eduedd8rf31/33Xefli1bZqo/AACAJqFOZ6rOnDmj4ODgatuDgoL4+A8AAFyT6hSqIiMjNWfOHJ09e9be9sMPP+jZZ59VZGSkseYAAACaijp9/Ldo0SKNGDFCnTp1Ut++fSVJf//73+Xr66uPPvrIaIMAAABNQZ1CVXh4uA4dOqTly5fr4MGDkqSxY8cqLi5O/v7+RhsEAABoCuoUqlJSUhQcHKwJEyZ4bH/jjTd08uRJTZ8+3UhzAAAATUWdrqn6wx/+oJ49e1bbfsMNNyg1NfWymwIAAGhq6hSqXC6XOnbsWG17hw4d9O233152UwAAAE1NnUJVaGiotm/fXm379u3b5XQ6L7spAACApqZOoWrChAmaMmWK3nzzTR09elRHjx7VG2+8oalTp1a7zupy/eMf/9D//M//qF27dvL391d4eLh2795tj1uWpeTkZHXs2FH+/v6KiorSoUOHPOYoLCxUXFycHA6HAgMDFR8fr9OnT3vU7Nu3T7feeqv8/PwUGhqq+fPnV+tl1apV6tmzp/z8/BQeHq4NGzYYPVYAANB01SlUPf3004qPj9djjz2m66+/Xtdff70mT56sxx9/XDNnzjTW3KlTp3TzzTerRYsW+uCDD/T5559rwYIFuu666+ya+fPna8mSJUpNTVVWVpZatWql6Ohoj3toxcXFKTc3VxkZGVq3bp22bdumiRMn2uNut1vDhw9Xly5dlJ2drRdffFFz587Va6+9Ztfs2LFDY8eOVXx8vPbs2aPY2FjFxsYqJyfH2PECAICmy8uyLKuuLz59+rQOHDggf39/de/eXb6+viZ704wZM7R9+3Z9/PHHNY5bliWn06knn3xSTz31lCSpuLhYwcHBSktL05gxY3TgwAH17t1bu3bt0sCBAyVJ6enpuvPOO/XNN9/I6XRq2bJleuaZZ+RyueTj42Pve82aNfYtI0aPHq2SkhKtW7fO3v/gwYPVr1+/Wl+c73a7FRAQoOLiYjkcjjq/LwAAVOk6Y31Dt9BoHHk+pl7mre3v7zqdqarSunVrDRo0SH369DEeqCRp7dq1GjhwoO69914FBQXpxhtv1Ouvv26PHz58WC6XS1FRUfa2gIAARUREKDMzU5KUmZmpwMBAO1BJUlRUlLy9vZWVlWXXDB061A5UkhQdHa28vDydOnXKrjl/P1U1VfupSWlpqdxut8cDAABcnS4rVNW3r7/+WsuWLVP37t314YcfatKkSXr88cf11ltvSfrxW4iSqv0dwuDgYHvM5XIpKCjIY7x58+Zq27atR01Nc5y/jwvVVI3XJCUlRQEBAfYjNDT0ko4fAAA0HY06VFVWVqp///763e9+pxtvvFETJ07UhAkTmsy9sGbOnKni4mL7cfz48YZuCQAA1JNGHao6duyo3r17e2zr1auXjh07JkkKCQmRJOXn53vU5Ofn22MhISEqKCjwGD937pwKCws9amqa4/x9XKimarwmvr6+cjgcHg8AAHB1atSh6uabb1ZeXp7Hti+++EJdunSRJIWFhSkkJEQbN260x91ut7KyshQZGSlJioyMVFFRkbKzs+2aTZs2qbKyUhEREXbNtm3bVF5ebtdkZGSoR48e9jcNIyMjPfZTVVO1HwAAcG1r1KFq6tSp+vTTT/W73/1OX375pVasWKHXXntNCQkJkiQvLy9NmTJF8+bN09q1a7V//349+OCDcjqdio2NlfTjma0RI0ZowoQJ2rlzp7Zv367ExESNGTPGvlHp/fffLx8fH8XHxys3N1crV67U4sWLlZSUZPfyxBNPKD09XQsWLNDBgwc1d+5c7d69W4mJiVf8fQEAAI1Pnf6g8pUyaNAgrV69WjNnztRvfvMbhYWFadGiRYqLi7Nrpk2bppKSEk2cOFFFRUW65ZZblJ6eLj8/P7tm+fLlSkxM1LBhw+Tt7a1Ro0ZpyZIl9nhAQIA++ugjJSQkaMCAAWrfvr2Sk5M97mU1ZMgQrVixQrNmzdKvf/1rde/eXWvWrFGfPn2uzJsBAAAatcu6TxUuDfepAgCYxn2q/qlJ36cKAAAAPyJUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMa9c0/AQC4GnAvqWsDZ6oAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABjRv6AYAAGgsus5Y39AtoAnjTBUAAIABhCoAAAADmlSoev755+Xl5aUpU6bY286ePauEhAS1a9dOrVu31qhRo5Sfn+/xumPHjikmJkYtW7ZUUFCQnn76aZ07d86jZsuWLerfv798fX3VrVs3paWlVdv/0qVL1bVrV/n5+SkiIkI7d+6sj8MEAABNUJMJVbt27dIf/vAH/exnP/PYPnXqVL3//vtatWqVtm7dqhMnTmjkyJH2eEVFhWJiYlRWVqYdO3borbfeUlpampKTk+2aw4cPKyYmRrfffrv27t2rKVOm6OGHH9aHH35o16xcuVJJSUmaM2eOPvvsM/Xt21fR0dEqKCio/4MHAACNnpdlWVZDN3Exp0+fVv/+/fXqq69q3rx56tevnxYtWqTi4mJ16NBBK1as0D333CNJOnjwoHr16qXMzEwNHjxYH3zwge666y6dOHFCwcHBkqTU1FRNnz5dJ0+elI+Pj6ZPn67169crJyfH3ueYMWNUVFSk9PR0SVJERIQGDRqkV155RZJUWVmp0NBQTZ48WTNmzKjVcbjdbgUEBKi4uFgOh8PkWwQAMIAL1Zu2I8/H1Mu8tf393STOVCUkJCgmJkZRUVEe27Ozs1VeXu6xvWfPnurcubMyMzMlSZmZmQoPD7cDlSRFR0fL7XYrNzfXrvnXuaOjo+05ysrKlJ2d7VHj7e2tqKgou6YmpaWlcrvdHg8AAHB1avS3VHjnnXf02WefadeuXdXGXC6XfHx8FBgY6LE9ODhYLpfLrjk/UFWNV439uxq3260ffvhBp06dUkVFRY01Bw8evGDvKSkpevbZZ2t3oAAAoElr1Geqjh8/rieeeELLly+Xn59fQ7dzyWbOnKni4mL7cfz48YZuCQAA1JNGHaqys7NVUFCg/v37q3nz5mrevLm2bt2qJUuWqHnz5goODlZZWZmKioo8Xpefn6+QkBBJUkhISLVvA1Y9v1iNw+GQv7+/2rdvr2bNmtVYUzVHTXx9feVwODweAADg6tSoQ9WwYcO0f/9+7d27134MHDhQcXFx9j+3aNFCGzdutF+Tl5enY8eOKTIyUpIUGRmp/fv3e3xLLyMjQw6HQ71797Zrzp+jqqZqDh8fHw0YMMCjprKyUhs3brRrAADAta1RX1PVpk0b9enTx2Nbq1at1K5dO3t7fHy8kpKS1LZtWzkcDk2ePFmRkZEaPHiwJGn48OHq3bu3HnjgAc2fP18ul0uzZs1SQkKCfH19JUmPPvqoXnnlFU2bNk0PPfSQNm3apHfffVfr1//zWyBJSUkaN26cBg4cqJtuukmLFi1SSUmJxo8ff4XeDQAA0Jg16lBVGwsXLpS3t7dGjRql0tJSRUdH69VXX7XHmzVrpnXr1mnSpEmKjIxUq1atNG7cOP3mN7+xa8LCwrR+/XpNnTpVixcvVqdOnfTHP/5R0dHRds3o0aN18uRJJScny+VyqV+/fkpPT6928ToAALg2NYn7VF0tuE8VADRu3KeqaeM+VQAAAFcBQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAAAAAwhVAAAABhCqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAY06lCVkpKiQYMGqU2bNgoKClJsbKzy8vI8as6ePauEhAS1a9dOrVu31qhRo5Sfn+9Rc+zYMcXExKhly5YKCgrS008/rXPnznnUbNmyRf3795evr6+6deumtLS0av0sXbpUXbt2lZ+fnyIiIrRz507jxwwAAJqmRh2qtm7dqoSEBH366afKyMhQeXm5hg8frpKSErtm6tSpev/997Vq1Spt3bpVJ06c0MiRI+3xiooKxcTEqKysTDt27NBbb72ltLQ0JScn2zWHDx9WTEyMbr/9du3du1dTpkzRww8/rA8//NCuWblypZKSkjRnzhx99tln6tu3r6Kjo1VQUHBl3gwAANCoeVmWZTV0E7V18uRJBQUFaevWrRo6dKiKi4vVoUMHrVixQvfcc48k6eDBg+rVq5cyMzM1ePBgffDBB7rrrrt04sQJBQcHS5JSU1M1ffp0nTx5Uj4+Ppo+fbrWr1+vnJwce19jxoxRUVGR0tPTJUkREREaNGiQXnnlFUlSZWWlQkNDNXnyZM2YMaPGfktLS1VaWmo/d7vdCg0NVXFxsRwOR728RwCAuus6Y31Dt4DLcOT5mHqZ1+12KyAg4KK/vxv1map/VVxcLElq27atJCk7O1vl5eWKioqya3r27KnOnTsrMzNTkpSZmanw8HA7UElSdHS03G63cnNz7Zrz56iqqZqjrKxM2dnZHjXe3t6Kioqya2qSkpKigIAA+xEaGno5hw8AABqxJhOqKisrNWXKFN18883q06ePJMnlcsnHx0eBgYEetcHBwXK5XHbN+YGqarxq7N/VuN1u/fDDD/ruu+9UUVFRY03VHDWZOXOmiouL7cfx48cv/cABAECT0LyhG6ithIQE5eTk6JNPPmnoVmrN19dXvr6+Dd0GAAC4AprEmarExEStW7dOmzdvVqdOneztISEhKisrU1FRkUd9fn6+QkJC7Jp//TZg1fOL1TgcDvn7+6t9+/Zq1qxZjTVVcwAAgGtboz5TZVmWJk+erNWrV2vLli0KCwvzGB8wYIBatGihjRs3atSoUZKkvLw8HTt2TJGRkZKkyMhIPffccyooKFBQUJAkKSMjQw6HQ71797ZrNmzY4DF3RkaGPYePj48GDBigjRs3KjY2VtKPH0du3LhRiYmJ9Xb8AIDquJgcjVWjDlUJCQlasWKF3nvvPbVp08a+fikgIED+/v4KCAhQfHy8kpKS1LZtWzkcDk2ePFmRkZEaPHiwJGn48OHq3bu3HnjgAc2fP18ul0uzZs1SQkKC/dHco48+qldeeUXTpk3TQw89pE2bNundd9/V+vX//A83KSlJ48aN08CBA3XTTTdp0aJFKikp0fjx46/8GwMAABqdRh2qli1bJkm67bbbPLa/+eab+tWvfiVJWrhwoby9vTVq1CiVlpYqOjpar776ql3brFkzrVu3TpMmTVJkZKRatWqlcePG6Te/+Y1dExYWpvXr12vq1KlavHixOnXqpD/+8Y+Kjo62a0aPHq2TJ08qOTlZLpdL/fr1U3p6erWL1wEAwLWpSd2nqqmr7X0uAAAXxsd/uBDuUwUAAHAVIFQBAAAY0KivqQIANF18TIdrDWeqAAAADCBUAQAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAf1AZABq5+vzDxEeej6m3uYFrDWeqAAAADCBUAQAAGMDHfwBwDavPjxaBaw1nqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIAB3FIBAAzh9gTAtY0zVQAAAAYQqgAAAAwgVAEAABhAqAIAADCAUAUAAGAAoQoAAMAAQhUAAIABhCoAAAADCFUAAAAGcEd1ANcU7noOoL5wpgoAAMAAQhUAAIABhCoAAAADuKYKQKPEtU8AmhrOVAEAABhAqAIAADCAj/8A1Bkf0QHAP3Gm6hItXbpUXbt2lZ+fnyIiIrRz586GbgkAADQChKpLsHLlSiUlJWnOnDn67LPP1LdvX0VHR6ugoKChWwMAAA2MUHUJXnrpJU2YMEHjx49X7969lZqaqpYtW+qNN95o6NYAAEAD45qqWiorK1N2drZmzpxpb/P29lZUVJQyMzNrfE1paalKS0vt58XFxZIkt9tdv80a1mfOhw3dAgAAF1Vfv1+r5rUs69/WEapq6bvvvlNFRYWCg4M9tgcHB+vgwYM1viYlJUXPPvtste2hoaH10iMAANeygEX1O//333+vgICAC44TqurRzJkzlZSUZD+vrKxUYWGh2rVrJy8vr4u+3u12KzQ0VMePH5fD4ajPVnEJWJfGhzVpfFiTxol1qRvLsvT999/L6XT+2zpCVS21b99ezZo1U35+vsf2/Px8hYSE1PgaX19f+fr6emwLDAy85H07HA7+5W+EWJfGhzVpfFiTxol1uXT/7gxVFS5UryUfHx8NGDBAGzdutLdVVlZq48aNioyMbMDOAABAY8CZqkuQlJSkcePGaeDAgbrpppu0aNEilZSUaPz48Q3dGgAAaGCEqkswevRonTx5UsnJyXK5XOrXr5/S09OrXbxuiq+vr+bMmVPtI0Q0LNal8WFNGh/WpHFiXeqXl3Wx7wcCAADgorimCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqurZtm3bdPfdd8vpdMrLy0tr1qzxGM/Pz9evfvUrOZ1OtWzZUiNGjNChQ4fs8cLCQk2ePFk9evSQv7+/OnfurMcff9z+O4JVjh07ppiYGLVs2VJBQUF6+umnde7cuStxiE3S5a7L+SzL0h133FHjPKxL7Zlak8zMTP3iF79Qq1at5HA4NHToUP3www/2eGFhoeLi4uRwOBQYGKj4+HidPn26vg+vSTKxJi6XSw888IBCQkLUqlUr9e/fX3/5y188aliT2ktJSdGgQYPUpk0bBQUFKTY2Vnl5eR41Z8+eVUJCgtq1a6fWrVtr1KhR1W5cXZufTVu2bFH//v3l6+urbt26KS0trb4Pr8kjVNWzkpIS9e3bV0uXLq02ZlmWYmNj9fXXX+u9997Tnj171KVLF0VFRamkpESSdOLECZ04cUK///3vlZOTo7S0NKWnpys+Pt6ep6KiQjExMSorK9OOHTv01ltvKS0tTcnJyVfsOJuay12X8y1atKjGPzvEulwaE2uSmZmpESNGaPjw4dq5c6d27dqlxMREeXv/80ddXFyccnNzlZGRoXXr1mnbtm2aOHHiFTnGpsbEmjz44IPKy8vT2rVrtX//fo0cOVL33Xef9uzZY9ewJrW3detWJSQk6NNPP1VGRobKy8s1fPhwj/d86tSpev/997Vq1Spt3bpVJ06c0MiRI+3x2vxsOnz4sGJiYnT77bdr7969mjJlih5++GF9+OGHV/R4mxwLV4wka/Xq1fbzvLw8S5KVk5Njb6uoqLA6dOhgvf766xec591337V8fHys8vJyy7Isa8OGDZa3t7flcrnsmmXLllkOh8MqLS01fyBXmctZlz179lg/+clPrG+//bbaPKxL3dV1TSIiIqxZs2ZdcN7PP//ckmTt2rXL3vbBBx9YXl5e1j/+8Q+zB3GVqeuatGrVynr77bc95mrbtq1dw5pcnoKCAkuStXXrVsuyLKuoqMhq0aKFtWrVKrvmwIEDliQrMzPTsqza/WyaNm2adcMNN3jsa/To0VZ0dHR9H1KTxpmqBlRaWipJ8vPzs7d5e3vL19dXn3zyyQVfV1xcLIfDoebNf7x3a2ZmpsLDwz1uQhodHS23263c3Nx66v7qVdt1OXPmjO6//34tXbq0xr//yLqYU5s1KSgoUFZWloKCgjRkyBAFBwfr5z//uceaZWZmKjAwUAMHDrS3RUVFydvbW1lZWVfoaK4Otf3vZMiQIVq5cqUKCwtVWVmpd955R2fPntVtt90miTW5XFWXgrRt21aSlJ2drfLyckVFRdk1PXv2VOfOnZWZmSmpdj+bMjMzPeaoqqmaAzUjVDWgqn/RZ86cqVOnTqmsrEwvvPCCvvnmG3377bc1vua7777Tb3/7W49T4y6Xq9pd3aueu1yu+juAq1Rt12Xq1KkaMmSI/vu//7vGeVgXc2qzJl9//bUkae7cuZowYYLS09PVv39/DRs2zL7Ox+VyKSgoyGPu5s2bq23btqzJJartfyfvvvuuysvL1a5dO/n6+uqRRx7R6tWr1a1bN0msyeWorKzUlClTdPPNN6tPnz6Sfnw/fXx8FBgY6FEbHBxsv5+1+dl0oRq32+1xjSI8EaoaUIsWLfTXv/5VX3zxhdq2bauWLVtq8+bNuuOOOzyuAanidrsVExOj3r17a+7cuVe+4WtEbdZl7dq12rRpkxYtWtSwzV4jarMmlZWVkqRHHnlE48eP14033qiFCxeqR48eeuONNxqy/atSbX9+zZ49W0VFRfrb3/6m3bt3KykpSffdd5/279/fgN1fHRISEpSTk6N33nmnoVvB/8ff/mtgAwYM0N69e1VcXKyysjJ16NBBERERHqfCJen777/XiBEj1KZNG61evVotWrSwx0JCQrRz506P+qpvetT0sRQu7mLrsmnTJn311VfV/m9w1KhRuvXWW7VlyxbWxbCLrUnHjh0lSb179/Z4Xa9evXTs2DFJP77vBQUFHuPnzp1TYWEha1IHF1uTr776Sq+88opycnJ0ww03SJL69u2rjz/+WEuXLlVqaiprUkeJiYn2Rf2dOnWyt4eEhKisrExFRUUeP5/y8/Pt97M2P5tCQkKqfWMwPz9fDodD/v7+9XFIVwXOVDUSAQEB6tChgw4dOqTdu3d7fKTkdrs1fPhw+fj4aO3atR7XMEhSZGSk9u/f7/GDKSMjQw6Ho9ovGFyaC63LjBkztG/fPu3du9d+SNLChQv15ptvSmJd6suF1qRr165yOp3Vvl7+xRdfqEuXLpJ+XJOioiJlZ2fb45s2bVJlZaUiIiKu3EFcZS60JmfOnJGkamfemzVrZp9ZZE0ujWVZSkxM1OrVq7Vp0yaFhYV5jA8YMEAtWrTQxo0b7W15eXk6duyYIiMjJdXuZ1NkZKTHHFU1VXPgAhr6Svmr3ffff2/t2bPH2rNnjyXJeumll6w9e/ZYR48etSzrx2/ybd682frqq6+sNWvWWF26dLFGjhxpv764uNiKiIiwwsPDrS+//NL69ttv7ce5c+csy7Ksc+fOWX369LGGDx9u7d2710pPT7c6dOhgzZw5s0GOuSm43HWpif7l21Gsy6UxsSYLFy60HA6HtWrVKuvQoUPWrFmzLD8/P+vLL7+0a0aMGGHdeOONVlZWlvXJJ59Y3bt3t8aOHXtFj7WpuNw1KSsrs7p162bdeuutVlZWlvXll19av//97y0vLy9r/fr1dh1rUnuTJk2yAgICrC1btnj8Pjhz5oxd8+ijj1qdO3e2Nm3aZO3evduKjIy0IiMj7fHa/Gz6+uuvrZYtW1pPP/20deDAAWvp0qVWs2bNrPT09Ct6vE0Noaqebd682ZJU7TFu3DjLsixr8eLFVqdOnawWLVpYnTt3tmbNmuXxdfsLvV6SdfjwYbvuyJEj1h133GH5+/tb7du3t5588kn7lguo7nLXpSb/Gqosi3W5FKbWJCUlxerUqZPVsmVLKzIy0vr44489xv/v//7PGjt2rNW6dWvL4XBY48ePt77//vsrcYhNjok1+eKLL6yRI0daQUFBVsuWLa2f/exn1W6xwJrU3oV+H7z55pt2zQ8//GA99thj1nXXXWe1bNnS+uUvf2l9++23HvPU5mfT5s2brX79+lk+Pj7W9ddf77EP1MzLsiyrPs+EAQAAXAu4pgoAAMAAQhUAAIABhCoAAAADCFUAAAAGEKoAAAAMIFQBAAAYQKgCAAAwgFAFAABgAKEKAADAAEIVAACAAYQqAGhgFRUVqqysbOg2AFwmQhUAnOftt99Wu3btVFpa6rE9NjZWDzzwgCTpvffeU//+/eXn56frr79ezz77rM6dO2fXvvTSSwoPD1erVq0UGhqqxx57TKdPn7bH09LSFBgYqLVr16p3797y9fXVsWPHrswBAqg3hCoAOM+9996riooKrV271t5WUFCg9evX66GHHtLHH3+sBx98UE888YQ+//xz/eEPf1BaWpqee+45u97b21tLlixRbm6u3nrrLW3atEnTpk3z2M+ZM2f0wgsv6I9//KNyc3MVFBR0xY4RQP3wsizLaugmAKAxeeyxx3TkyBFt2LBB0o9nnpYuXaovv/xS//mf/6lhw4Zp5syZdv2f/vQnTZs2TSdOnKhxvj//+c969NFH9d1330n68UzV+PHjtXfvXvXt27f+DwjAFUGoAoB/sWfPHg0aNEhHjx7VT37yE/3sZz/Tvffeq9mzZ6tDhw46ffq0mjVrZtdXVFTo7NmzKikpUcuWLfW3v/1NKSkpOnjwoNxut86dO+cxnpaWpkceeURnz56Vl5dXAx4pAJOaN3QDANDY3Hjjjerbt6/efvttDR8+XLm5uVq/fr0k6fTp03r22Wc1cuTIaq/z8/PTkSNHdNddd2nSpEl67rnn1LZtW33yySeKj49XWVmZWrZsKUny9/cnUAFXGUIVANTg4Ycf1qJFi/SPf/xDUVFRCg0NlST1799feXl56tatW42vy87OVmVlpRYsWCBv7x8vW3333XevWN8AGg6hCgBqcP/99+upp57S66+/rrffftvenpycrLvuukudO3fWPffcI29vb/39739XTk6O5s2bp27duqm8vFwvv/yy7r77bm3fvl2pqakNeCQArhS+/QcANQgICNCoUaPUunVrxcbG2tujo6O1bt06ffTRRxo0aJAGDx6shQsXqkuXLpKkvn376qWXXtILL7ygPn36aPny5UpJSWmgowBwJXGhOgBcwLBhw3TDDTdoyZIlDd0KgCaAUAUA/+LUqVPasmWL7rnnHn3++efq0aNHQ7cEoAngmioA+Bc33nijTp06pRdeeIFABaDWOFMFAABgABeqAwAAGECoAgAAMIBQBQAAYAChCgAAwABCFQAAgAGEKgAAAAMIVQAAAAYQqgAAAAz4f5e6jBBWXVVZAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Range: 1922 - 2011\n",
            "Unique values: 89\n"
          ]
        }
      ],
      "source": [
        "plt.hist(df.iloc[:, 0], bins=20)\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n",
        "print(f'Range: {df.iloc[:, 0].min()} - {df.iloc[:, 0].max()}')\n",
        "print(f'Unique values: {np.unique(df.iloc[:, 0]).size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9a-eJUG35C3"
      },
      "source": [
        "Разобьем данные на обучение и тест (не меняйте здесь ничего, чтобы сплит был одинаковым у всех)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((386508, 90), (128837, 90))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "train_size = int(0.75 * X.shape[0])\n",
        "\n",
        "X_train = X[:train_size, :]\n",
        "y_train = y[:train_size]\n",
        "X_test = X[train_size:, :]\n",
        "y_test = y[train_size:]\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Полезные советы:\n",
        "\n",
        "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
        "\n",
        "- Если вы чего-то не знаете, не стесняйтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению и `pytorch`. Но не забывайте, что за списанный код без ссылки на источник последует наказание.\n",
        "\n",
        "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так.\n",
        "\n",
        "- Пользуйтесь утилитами, которые вам предоставляет `pytorch` (например, `Dataset` и `Dataloader`). Их специально разработали для упрощения разработки пайплайна обучения.\n",
        "\n",
        "- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
        "\n",
        "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
        "\n",
        "- При желании вы можете логгировать метрики обучения и свои эксперименты в WandB либо любой другой сервис. Не забудьте приложить к тетрадке ссылку на результаты экспериментов либо скришноты графиков с пояснениями, что проверяющий должен на них увидеть.\n",
        "\n",
        "\n",
        "- Финальное значение тестовой метрики для удобства проверки выведите в тетрадке.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_386JE_o5gOd"
      },
      "source": [
        "## Задание 0 (0 баллов, но при невыполнении максимальная оценка за всю работу &mdash; 0 баллов)\n",
        "\n",
        "Мы будем использовать RMSE как метрику качества. Прежде чем обучать нейронные сети, нам нужно проверить несколько простых бейзлайнов, чтобы было с чем сравнить более сложные алгоритмы. Для этого бучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе.\n",
        "\n",
        "Для выполнения данного задания (и всех последующих) предобработайте данные.\n",
        "\n",
        "1. Зафиксируйте random_seed везде где только возможно. Вам предоставлена функция для этого, однако вы можете дополнить ее своими дополнениями.\n",
        "2. Обучите `StandertScaler` и предобработайте ваши данные. В следующих заданиях можете использовать другой `scaler` или вообще отказаться от него.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lkfkXylb8U-O"
      },
      "outputs": [],
      "source": [
        "def set_global_seed(seed: int) -> None:\n",
        "    \"\"\"Set global seed for reproducibility.\n",
        "    :param int seed: Seed to be set\n",
        "    \"\"\"\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # также можно зафиксировать seed для Dataloader\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(seed)\n",
        "    return g\n",
        "\n",
        "# Сид для каждого worker в Dataloader\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = set_global_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKVVatBw8cH7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "model = ...\n",
        "rmse_for_model = ...\n",
        "\n",
        "# your code here  ⟅⎰᨟﹏᨟⎱⟆"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJKGuhFi35C4"
      },
      "source": [
        "Лучшая константа для RMSE это среднее. Используйте среднее, расчитанное на трэйне в качестве прогноза для теста и посчитайте для такой наивной модели RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOcFuy1P35C4"
      },
      "outputs": [],
      "source": [
        " # your code here  ⟅⎛ꌩωꌩ⎞⟆\n",
        "best_rmse_metric = ... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь приступим к экспериментам с нейросетями. Для начала отделим от данных валидацию. Тестовую выборку мы будем использовать только для того, чтобы измерить итоговую метрику качества модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0xE2E4)\n",
        "X_train.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Часть I. Обучаем линейную регрессию (максимум 10 баллов)\n",
        "\n",
        "**Задание 1 (10 баллов):** Обучите в `pytorch` линейную регрессию. \n",
        "\n",
        "- Создайте модель линейной регрессии, которая будет состоять только из одного `Linear()` слоя.\n",
        "   \n",
        "- Напишите цикл обучения вашей линейной регрессии. В нем реализуйте подсчет функции потерь, сделайте шаг градиентного спуска. Запрещено использовать готовые оптимизаторы и loss-функции из библиотеки `pytorch`. Для подсчета градиента воспользуйтесь методом backward.\n",
        "   \n",
        "- Запустите обучение на 10 эпохах, после каждой проверяйте значение целевой метрики на тестовой выборке.\n",
        "   \n",
        "- Выведите на экран графики метрики и значения функции потерь на тестовой и обучающей выборке.\n",
        "\n",
        "В данном задании нет цели побить какой-то порог по метрике. Ваша задача &mdash; убедиться в том, что ваш рукописный цикл обучения работает. Для ускорения вычислений и обучения модели можете брать только срез данных, а не весь датасет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here (ง •̀_•́)ง"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Часть II. Заводим нейронную сеть (максимум 10 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ниже нам предстоит реализовать довольно много различных нейросетей и поставить целую серию экспериментов. Чтобы это всё происходило без боли и страданий, нам нужно держать код в удобном виде.\n",
        "\n",
        "При реении заданий вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться сигнатурами функций, которые приведены ниже. При необходимости вы можете добавить в них любые нужные вам аргументы и любой нужный функционал. Более того, хорошей практикой является не делать эти функции слишком громздкими и выносить разные хитрые штуки в отдельные функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_epoch(model, optimizer, criterion, train_loader):\n",
        "    \"\"\"Одна эпоха обучения\n",
        "    params:\n",
        "        model - torch.nn.Module to be fitted\n",
        "        optimizer - model optimizer\n",
        "        criterion - loss function from torch.nn\n",
        "        train_loader - torch.utils.data.Dataloader with train set\n",
        "    \"\"\"\n",
        "\n",
        "    # your code here  ♪┏(・o･)┛♪\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def validation_epoch(model, criterion, val_loader):\n",
        "    \"\"\"Одна эпоха валидации модели\n",
        "    params:\n",
        "        model - torch.nn.Module to be fitted\n",
        "        criterion - loss function from torch.nn\n",
        "        val_loader - torch.utils.data.Dataloader with test set\n",
        "                      (if you wish to validate during training)\n",
        "    \"\"\"\n",
        "\n",
        "    # your code here   ฅ^•ﻌ•^ฅ \n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(model, data_loader):\n",
        "    \"\"\" Предсказания модели\n",
        "    params:\n",
        "        model - torch.nn.Module to be evaluated on test set\n",
        "        criterion - loss function from torch.nn\n",
        "        data_loader - torch.utils.data.Dataloader with test set\n",
        "    ----------\n",
        "    returns:\n",
        "        predicts - torch.tensor with shape (len(test_loader.dataset), ),\n",
        "                   which contains predictions for test objects\n",
        "    \"\"\"\n",
        "    \n",
        "    # your code here  =^･ω･^=\n",
        "\n",
        "    predicts = torch.ones(len(test_loader.dataset))\n",
        "    return predicts\n",
        "\n",
        "\n",
        "def train(model, optimizer, criterion, train_loader, val_loader, epochs):\n",
        "    \"\"\" Обучение модели\n",
        "    params:\n",
        "        model - torch.nn.Module to be fitted\n",
        "        optimizer - model optimizer\n",
        "        criterion - loss function from torch.nn\n",
        "        train_loader - torch.utils.data.Dataloader with train set\n",
        "        val_loader - torch.utils.data.Dataloader with test set\n",
        "                      (if you wish to validate during training)\n",
        "        epochs - number of training epochs\n",
        "    \"\"\"\n",
        "    \n",
        "    # your code here  ¯\\_(ツ)_/¯\n",
        "\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 2 (2 балла)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Попробуем обучить нашу первую нейронную сеть. Здесь целевая переменная дискретная &mdash; это год выпуска песни. Поэтому будем учить сеть на классификацию.\n",
        "\n",
        "- В качестве архитектуры сети возьмите два линейных слоя с активацией ReLU между ними c числом скрытых нейронов, равным 128.\n",
        "- Используйте SGD с `lr=1e-3`.\n",
        "- Возьмите размер мини-батча около 32-64, примерно 3-4 эпох обучения должно быть достаточно.\n",
        "- Также преобразуйте целевую переменную так, чтобы ее значения принимали значения от $0$ до $C-1$, где $C$ &mdash; число классов (лучше передайте преобразованное значение в DataLoader, исходное нам еще пригодится)\n",
        "- В качестве метрики качества мы используем RMSE. При его подсчёте вам нужно заменить предсказанный нейросеткой класс на конкретный год выпуска песни и использовать его как прогноз. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here (￣ω￣)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 3 (1 балл).** Прокомментируйте ваши наблюдения. Удалось ли побить бейзлайн? Как вы думаете, хорошая ли идея учить классификатор для этой задачи? Почему?\n",
        "\n",
        "**Ответ:** ... \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 4 (2 балла).** Теперь попробуем решать задачу как регрессию. Обучите нейронную сеть на MSE.\n",
        "\n",
        "- Используйте такие же гиперпараметры обучения.\n",
        "- Когда передаете целевую переменную в DataLoader, сделайте reshape в (-1, 1).\n",
        "- Если что-то пойдет не так, можете попробовать меньшие значения `lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here ( ⚆ _ ⚆)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 5 (1 балл).** Получилось ли у вас стабилизировать обучение? Помогли ли меньшие значения `lr`? Стало ли лучше от замены классификации на регрессию? Как вы думаете, почему так происходит? В качестве подсказки можете посмотреть на распределение целевой переменной и магнитуду значений признаков.\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 6 (1 балл).** Начнем с того, что попробуем отнормировать целевую переменную. Для этого воспользуемся min-max нормализацией, чтобы целевая переменная принимала значения от 0 до 1. Реализуйте функции `normalize` и `denormalize`, которые, соответственно, нормируют целевую переменную и применяют обратное преобразование. Минимум и максимум оцените по обучающей выборке (то есть эти константы должны быть фиксированными и не зависеть от передаваемой выборки)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(sample):\n",
        "    \"\"\"\n",
        "    Min-max normalization to convert sample to [0, 1] range\n",
        "    \"\"\"\n",
        "    # your code here ᕦ(ò_óˇ)ᕤ\n",
        "    pass\n",
        "\n",
        "def denormalize(sample):\n",
        "    \"\"\"\n",
        "    Denormalize sample from [0, 1] to initial range\n",
        "    \"\"\"\n",
        "    # your code here ( ⚆ ω ⚆)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 7 (1 балл)** Теперь повторите эксперимент из **задания 4**, обучаясь на нормированной целевой переменной. Сделаем также еще одно изменение: добавим сигмоидную активацию после последнего линейного слоя сети. Таким образом мы гарантируем, что нейронная сеть предсказывает числа из промежутка $[0, 1]$. Использование активации - довольно распространенный прием, когда мы хотим получить числа из определенного диапазона значений. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here  ლ(ಠ益ಠლ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 8 (2 балла).** На этот раз попробуем отнормировать не только целевую переменную, но и сами данные, которые подаются сети на вход. Для них будем использовать нормализацию через среднее и стандартное отклонение. Преобразуйте данные и повторите прошлый эксперимент. Скорее всего, имеет смысл увеличить число эпох обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        " # your code here  ( ͡° ͜ʖ ͡°)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Если вы все сделали правильно, то у вас должно было получиться качество, сравнимое с `Ridge` регрессией.\n",
        "\n",
        "**Мораль:** как видите, нам пришлось сделать очень много хитрых телодвижений, чтобы нейронная сеть работала хотя бы так же, как и простая линейная модель. Здесь, конечно, показан совсем экстремальный случай, когда без нормализации данных нейронная сеть просто не учится. Как правило, в реальности завести нейронную сеть из коробки не очень сложно, но вот заставить ее работать на полную &mdash; куда более трудоемкая задача. Написание пайплайнов обучения нейросетевых моделей требует большой аккуратности, а дебаг часто превращается в угадайку. К счастью, очень часто на помощь приходит интуиция, и мы надеемся, что вы сможете выработать ее в течение нашего курса. Начнем с двух советов, которые стоит принять на вооружение:\n",
        "\n",
        "- Обязательно начинаем любые эксперименты с бейзлайнов: без них мы бы не поняли, что нейронная сеть не учится в принципе.\n",
        "- При постановке эксперментов старайтесь делать минимальное количество изменений за раз (в идеале одно!): только так можно понять, какие конкретно изменения влияют на результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Часть III. Улучшаем нейронную сеть (максимум 10 баллов)\n",
        "\n",
        "Продолжим экспериментировать с нейронной сетью, чтобы добиться еще лучшего качества."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 9 (1 балл).** Давайте попробуем другие оптимизаторы. Обучите нейросеть с помощью SGD+momentum и Adam. Опишите свои наблюдения и в дальнейших запусках используйте лучший оптимизатор. Для Adam обычно берут learning rate поменьше, в районе $10^{-3}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here  ( ཀ ʖ̯ ཀ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 10 (1 балл).** Теперь сделаем нашу нейронную сеть более сложной. Попробуйте сделать сеть:\n",
        "\n",
        "- более широкой (то есть увеличить размерность скрытого слоя, например, вдвое)\n",
        "- более глубокой (то есть добавить еще один скрытый слой)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here  (๑-﹏-๑)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Опишите, как увеличение числа параметров модели влияет на качество на обучающей и валидационной выборках (без их описания за работу ставится ноль баллов)\n",
        "\n",
        "__Ваше подробное описание:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 11 (1 балл).** Как вы должны были заметить, более сложная модель стала сильнее переобучаться. Попробуем разные методы регуляризации, чтобы бороться с переобучением. Проведите два эксперимента:\n",
        "\n",
        "- Добавьте слой дропаута с параметром $p=0.2$ после каждого линейного слоя, кроме последнего.\n",
        "- Попробуйте batch-нормализацию вместо дропаута. Строго говоря, batch-нормализация не является методом регуляризации, но никто не запрещает нам экспериментировать с ней."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here (❍ᴥ❍ʋ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Опишите результаты экспериментов (без их описания за работу ставится ноль баллов)\n",
        "\n",
        "__Ваше подробное описание:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 12 (1 балл).** Теперь, когда мы определились с выбором архитектуры нейронной сети, пора заняться рутиной DL-инженера &mdash; перебором гиперпараметров. Подберите оптимальное значение lr по значению RMSE на валидации (по логарифмической сетке, достаточно посмотреть 3-4 значения). Затем подберите оптимальное значение weight decay для данного lr (тоже по логарифмической сетке, типичные значения этого параметра лежат в диапазоне $[10^{-6}, 10^{-3}]$, но не забудьте включить нулевое значение в сетку). Постройте графики зависимости RMSE на трейне и на валидации от значений параметров. Прокомментируйте получившиеся зависимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here (｡❤‿❤｡)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Опишите результаты экспериментов (без их описания за работу ставится ноль баллов)\n",
        "\n",
        "__Ваше подробное описание:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Как вы могли заметить, еще одна рутина DL-инженера &mdash; утомительное ожидание обучения моделей.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание 13 (6 баллов).**\n",
        "\n",
        "Думаю направление размышлений вы поняли. Постарайтесь с помощью своих экспериментов выбить максимально возможное значение RMSE на тестовой выборке. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
        "\n",
        "- $\\text{RMSE} \\le 8.90 $ &mdash; 2 балла\n",
        "- $\\text{RMSE} \\le 8.80 $ &mdash; 4 балла\n",
        "- $\\text{RMSE} \\le 8.75 $ &mdash; 6 баллов\n",
        "\n",
        "**Различные трюки, которые можно попробовать:**\n",
        "\n",
        "1. Попробуйте делать во время обучения раннюю остановку обучения и сохранять модель в тот момент, когда качество на валидации начало ухудшаься, то есть модель начала переобучаться\n",
        "2. Попробуйте усложнить архитектуру нейросет\n",
        "    - Больше/меньше нейронов\n",
        "    - Больше/меньше слоёв\n",
        "    - Другие функции активации (tanh, relu, leaky relu, elu etc)\n",
        "    - Регуляризация (dropout, l1,l2)\n",
        "3. Попробуйте другие оптимизаторы, а также смену скорости обучения по расписанию.\n",
        "\n",
        "И это далеко не полный список. Обратите внимание, что делать grid_search для больших сеток это довольно времязатратное занятие... Попробовать несколько значений, как мы делали в заданиях выше, адекватно, но делать какой-то огромный перебор будет самоубийством.\n",
        "\n",
        "Логгируйте свои эксперименты. За один прогон пробуйте одно изменение. Иначе будет непонятно какие именно изменения улучшили качество, а какие ухудшили. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n",
        "# ༼ つ ಥ_ಥ ༽つ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Опишите результаты экспериментов (без их описания за работу ставится ноль баллов)\n",
        "\n",
        "__Ваше подробное описание:__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Бонус (0.1 балла)\n",
        "\n",
        "Прикрепите фотографию того, как вы начали этот сентябрь. Какую самую классную эмоцию вы испытали за прошедший месяц?\n",
        "\n",
        "__место для картики и эмоции__\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
