{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 5: Transfer Learning, Adversarial Attacks, Deep Network Visualization\n",
    "\n",
    "## Вступление\n",
    "Сегодня мы продолжим работать с изображениями при помощи нейросетей. Сперва узнаем, как потратить мало вычислительных ресурсов, чтобы при наличии модели для одной задачи, научиться решат новую задачу. Затем посмотрим на то, как можно за один шаг обучения сбивать нейросети с толку на некоторых примерах. В конце семинара будем визуализировать работу свёрточных сетей.\n",
    "\n",
    "Этот ноутбук, в отличие от предыдущих, очень рекомендуется исполнять в Google Colab или похожих платформах, чтобы всю работало побыстрее.\n",
    "\n",
    "### План семинара\n",
    "1. Изучаем transfer learning на примере файнтюнинга ResNet\n",
    "2. Изучаем adversarial attacks на примере Fast Gradient Sign Attack\n",
    "3. Визуализируем слои свёрточной сети при помощи Shapley Additive Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Изучаем transfer learning на примере файнтюнинга ResNet\n",
    "\n",
    "В этой секции мы научимся очень быстро обучать нейросеть на сложную задачу классификации изображений. А именно, научим нейросеть отличать кошечек от собаче.\n",
    "\n",
    "### Данные\n",
    "\n",
    "Скачем датасет, удалим пару битых картинок и подготовим лоадеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
    "# !unzip -qq kagglecatsanddogs_5340.zip\n",
    "# !rm -rf PetImages/Cat/666.jpg PetImages/Dog/11702.jpg readme\\[1\\].txt CDLA-Permissive-2.0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(\n",
    "    \"./PetImages\", \n",
    "    transform=Compose(\n",
    "        [\n",
    "            Resize((224, 224)), \n",
    "            ToTensor(), \n",
    "            Normalize((0.5, 0.5, 0.5), (1, 1, 1)), \n",
    "        ]\n",
    "    )\n",
    ")\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    dataset, \n",
    "    [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))]\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят картинки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.random.choice(glob.glob(\"./PetImages/*/*.jpg\"))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(plt.imread(file));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "Кошки и собаки — это, конечно, хорошо, вот только обучение модели, которая будет хорошо работать на этом датасете может оказаться очень долгим...\n",
    "\n",
    "Однако картинки, которые мы сегодня рассмотрим, оказываются очень похожими на картинки из огромного датасета ImageNet. Задача, которую мы сегодня рассмотрим, называется Transfer Learning. Знания мы действительно переносим — от сети, которая хорошо работает на одном датасете (ImageNet) к другим данным (к датасету Cats vs Dogs).\n",
    "\n",
    "#### Загрузим уже обученную сеть\n",
    "\n",
    "В библиотеке `torchvision` имплементировано не только большое множество моделей (всевозможные ResNet'ы, Inception, VGG, AlexNet, DenseNet, ResNext, WideResNet, MobileNet...), но и загружены чекпоинты обучения этих моделей на ImageNet. Однако для датасета Cats vs Dogs такая штука является роскошью..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче transfer learning'a мы заменяем последний слой нейросети на линейный с двумя выходами, а веса остальных слоёв \"замораживаем\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatsVSDogsResnet(pl.LightningModule):\n",
    "    def __init__(self, pretrained: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        if pretrained:\n",
    "            # <YOUR CODE HERE>\n",
    "        else:\n",
    "            # <YOUR CODE HERE>\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        if self.pretrained:\n",
    "            # <YOUR CODE HERE>\n",
    "            with torch.no_grad():\n",
    "        else:\n",
    "            # <YOUR CODE HERE>\n",
    "        return preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx) -> torch.Tensor:\n",
    "        images, target = train_batch\n",
    "        preds = self.forward(images)\n",
    "        loss = self.loss(preds, target)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx) -> None:\n",
    "        images, target = val_batch\n",
    "        preds = self.forward(images)\n",
    "        loss = self.loss(preds, target)\n",
    "        acc = accuracy(torch.argmax(preds, dim=-1).long(), target.long())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"accuracy\", acc, prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cats_vs_dogs_pretrained = CatsVSDogsResnet(pretrained=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    max_epochs=1\n",
    ")\n",
    "trainer.fit(cats_vs_dogs_pretrained, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже после одной эпохи получается приемлемое качество! Давайте проверим, что получится, если учить ResNet с нуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cats_vs_dogs = CatsVSDogsResnet(pretrained=False)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    max_epochs=1\n",
    ")\n",
    "trainer.fit(cats_vs_dogs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, на transfer learning'e нейросеть сходится очень быстро. Значительно быстрее, чем инициализированная с нуля. Можно с уверенностью говорить, что transfer learning — очень полезная техника."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Изучаем adversarial attacks на примере Fast Gradient Sign Attack\n",
    "\n",
    "Такая вещь, как атаки на нейросеть крайне важны для учёта при разработке. Существует много методов как их генерации, так и защиты от них. Мы рассмотрим сегодня базовые концепты, чтобы дать понимание происходящего.\n",
    "\n",
    "Можем назвать adversarial атакой генерацию такого примера, который не отличим глазом от настоящего, но нейросеть будет ОЧЕНЬ уверена в том, что этот пример из другого класса. Сейчас мы попробуем сгенерировать такую собачку, что нейросеть будет уверена, что это котик.\n",
    "\n",
    "Сегодня мы рассмотрим пример Fast Gradient Sign Attack (FGSM, почему там буква M в конце — чёрт его знает...). Идея очень простая. Оказывается, что если мы через обученную нейросеть посчитаем градиент по исходной картинке, посчитаем его знак и прибавим, умножив на маленькое число, модель подумает, что это картинка другого класса.\n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/fgsm_panda_image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fgsm_attack(\n",
    "        original_image: torch.Tensor,\n",
    "        epsilon: float,\n",
    "        data_grad: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    # <YOUR CODE HERE>\n",
    "    return perturbated_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    cats_vs_dogs_pretrained.model,\n",
    "    cats_vs_dogs_pretrained.classifier\n",
    ")\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # ищем кошку\n",
    "    idx = np.random.randint(0, len(train_set))\n",
    "    if train_set[idx][1] != 0:\n",
    "        continue\n",
    "    cat_image = train_set[idx][0]\n",
    "    break\n",
    "\n",
    "# Разрешим вычисление градиента по картинке\n",
    "cat_image.requires_grad = True\n",
    "\n",
    "pred = model(cat_image[None])\n",
    "predicted_label = pred.argmax(1).item()\n",
    "confidence = pred.softmax(1)[0][predicted_label]\n",
    "if predicted_label == 1:\n",
    "    plt.title(\"Dog, confidence = %0.4f\" % confidence.item())\n",
    "else:\n",
    "    plt.title(\"Cat, confidence =  %0.4f\" % confidence.item())\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cat_image.cpu().detach().numpy().transpose((1, 2, 0)) + 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()(pred, torch.tensor(cl).reshape((1,)))\n",
    "loss.backward()\n",
    "\n",
    "eps = 0.007\n",
    "\n",
    "cat_image_perturbated = fgsm_attack(cat_image, eps, cat_image.grad)\n",
    "pred = model(cat_image_perturbated[None])\n",
    "predicted_label = pred.argmax(1).item()\n",
    "confidence = pred.softmax(1)[0][predicted_label]\n",
    "\n",
    "plt.axis(\"off\")\n",
    "if predicted_label == 1:\n",
    "    plt.title(\"Dog, confidence = %0.4f\" % confidence.item())\n",
    "else:\n",
    "    plt.title(\"Cat, confidence =  %0.4f\" % confidence.item())\n",
    "plt.imshow(cat_image_perturbated.cpu().detach().numpy().transpose((1, 2, 0)) + 0.5);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое интересное начинается тут. Вычислим градиент функции потерь по картинке и произведём атаку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Визуализируем слои свёрточной сети при помощи Shapley Additive Explanations\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_header.svg\" />\n",
    "\n",
    "**SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations).\n",
    "\n",
    "Представим, что предсказание - результат командной игры и нужно понять, какой вклад в какое место результат внес каждый игрок(фича).\n",
    "\n",
    "Вклад каждой фичи измеряется так называемой **Shapley value** - понятием из **cooperative game theory**, описывающим вклад фичи в предсказание.\n",
    "\n",
    "Например, вы снимаете однушку в Москве и хотите создать модель, которая предскажет стоимость выбранного вами варианта. Для заданной квартиры модель предсказала цену 50.000 р. Свойства квартиры, по которой была предсказана цена: в пределах мкада, есть кондиционер, с домашними крокодилами нельзя, рядом находится парк. Нужно найти **Shapley value** свойства \"с крокодилами нельзя\", чтобы понять, насколько большой вклад вносит именно этот признак.\n",
    "\n",
    "**Shapley value** это среднее от возможных **marginal contributions**. Мы создаем все возможные наборы над множеством свойств, исключая интересующее (\"с крокодилами нельзя\"):\n",
    "\n",
    "\n",
    "*   ни одного свойства\n",
    "*   в пределах мкада\n",
    "*   кондей\n",
    "*   рядом парк\n",
    "*   в пределах мкада, кондей\n",
    "*   в пределах мкада, рядом парк\n",
    "*   кондей, рядом парк\n",
    "*   в пределах мкада, рядом парк, кондей\n",
    "\n",
    "\n",
    "Пример для маржинального вклада:\n",
    "\n",
    "**Marginal contribution** = *model_predict* (в пределах мкада, рядом парк, с крокодилами нельзя) -  *model_predict* (в пределах мкада, рядом парк)\n",
    "\n",
    "$$\n",
    "\\Phi(v)_i=\\sum_{K \\ni i} \\frac{(k-1) !(n-k) !}{n !}(v(K)-v(K \\backslash i))\n",
    "$$\n",
    "\n",
    "Где: $n$ — количество игроков (в нашем случае это признаки модели). $v$ — предсказание модели на наборе признаков. $k$ — количество участников коалиции $K$.\n",
    "\n",
    "Предсказание можно объяснить, предположив, что каждый признак является “игроком” в игре, где предсказание является выплатой. Значения Шепли – метод из теории коалиционных игр – подсказывает нам, как справедливо распределить “выплату” между признаками.\n",
    "\n",
    "Документация по [cсылкe](https://shap.readthedocs.io/en/latest/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучаем слои ResNet на данных ImageNet\n",
    "\n",
    "Трактовка предсказаний на основе оригинальной картинки проще, чем на основе слоёв, которые ближе всего к выходу сети, потому что последние менее интерпретируемы. Каждый уровень в deep CNN изучает фильтры возрастающей сложности. На первых слоях изучаются основные фильтры обнаружения объектов, такие как края и углы. Средние слои изучают фильтры, которые обнаруживают части объектов — что касается лиц, они могут научиться реагировать на глаза и носы. Последние слои имеют более высокие представления: они учатся распознавать объекты целиком, в различных формах и положениях.\n",
    "\n",
    "Мы рассмотрим модель GradientExplainer, которая использует ожидаемые градиенты для оценки входов в разные части модели. В целом, они аппроксимируют значения SHAP. Будем брать 50 семплов для подсчёта ожидаемых градиентов и посмотрим на признаки первых слоёв ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize(image):\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "    image = (image - mean) / std\n",
    "    # in addition, roll axes so that they suit pytorch\n",
    "    return torch.tensor(image.swapaxes(-1, 1).swapaxes(2, 3)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load proper model (resnet50) and data (imagenet50) from Shap wrapper\n",
    "model = resnet18(pretrained=True).eval()\n",
    "X, y = shap.datasets.imagenet50()\n",
    "X /= 255\n",
    "\n",
    "to_explain = X[[1, 41]]\n",
    "\n",
    "# load the ImageNet class names\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "fname = shap.datasets.cache(url)\n",
    "\n",
    "with open(fname) as f:\n",
    "    class_names = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# create GradientExplainer object for convolution layer from Resnet Layer1\n",
    "e = shap.GradientExplainer((model, model.layer1[0].conv2), normalize(X))\n",
    "# receive shap_values\n",
    "shap_values, indexes = e.shap_values(normalize(to_explain), ranked_outputs=4, nsamples=50)\n",
    "\n",
    "# get the names for the classes\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "# plot the explanations\n",
    "shap_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
    "\n",
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "e = shap.GradientExplainer((model, model.layer2[0].conv2), normalize(X))\n",
    "shap_values, indexes = e.shap_values(normalize(to_explain), ranked_outputs=4, nsamples=50)\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "shap_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "e = shap.GradientExplainer((model, model.layer4[0].conv2), normalize(X))\n",
    "shap_values, indexes = e.shap_values(normalize(to_explain), ranked_outputs=4, nsamples=50)\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "shap_values = [np.swapaxes(np.swapaxes(s, 2, 3), 1, -1) for s in shap_values]\n",
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
