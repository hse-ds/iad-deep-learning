{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 4: Методы оптимизации, PyTorch Lightning\n",
    "\n",
    "## Вступление\n",
    "На предыдущем курсе мы обсуждали с вами методы градиентного спуска и стохастического градиентного спуска. Для нейронных сетей обычно используют более продвинутые методы оптимизации, которые основаны на известном нам градиентном спуске. Сегодня мы посмотрим на то, как использовать их в **PyTorch**, а также разберём библиотеку **PyTorch Lightning**, позволяющую сократить количество кода, которое нам приходится писать на **PyTorch**.\n",
    "\n",
    "### План семинара\n",
    "1. Оптимизируем функцию одной переменной в **PyTorch**\n",
    "2. Изучаем разные методы оптимизации\n",
    "3. Работаем с PyTorch Optimizer\n",
    "4. Работаем с PyTorch Scheduler\n",
    "5. PyTorch VS PyTorch Lightning\n",
    "6. Сравним работу разных оптимизаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pytorch_lightning torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUJcEdalKlZn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGd36K4dlgL5"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    # фискирует максимум сидов для корректности сравнения разных экспериментов\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(0xBADBEEF)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Our device is \"{device}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD68Ub9hKlZy"
   },
   "source": [
    "## Оптимизируем функцию одной переменной в **PyTorch**\n",
    "Как вам показали на лекции, большинство методов машинного обучения сводятся к простому поиску параметров, который бы минимизировал ошибку на тренировочной выборке:\n",
    "$$\n",
    "\\min_{\\theta}L(p_{\\theta}(X), Y)\n",
    "$$\n",
    "Здесь:\n",
    "* $L$ - некоторый лосс,\n",
    "* $p_{\\theta}$ - нейронная сеть с параметрами $\\theta$\n",
    "* $X$ - данные для обучения,\n",
    "* $Y$ - ответы\n",
    "\n",
    "Давайте руками напишем алгоритм для поиска минимума функции $f(x) = x^{3} - 2x^{2} + 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6RDPRKKHKlZ0",
    "outputId": "0b601ca0-361f-4dc2-e46b-62f143279478"
   },
   "outputs": [],
   "source": [
    "# наша функция f(x)\n",
    "func = lambda x: x**3 - 2 * x**2 + 2\n",
    "# производная функции f(x)\n",
    "d_func = lambda x: 3 * x**2 - 4 * x\n",
    "# сделаем массив из 1000 элементов от -3 до 3\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "# определим границы по y для графика\n",
    "plt.ylim([-1, 3])\n",
    "plt.plot(x, func(x))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYQ4OyiUKlZ4"
   },
   "source": [
    "Определим функцию для оптимизации $f(x)$, которая должна принимать на вход learning rate и максимальное количество итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQ_QI8CiKlZ5"
   },
   "outputs": [],
   "source": [
    "def find_minimum_first_order(\n",
    "    learning_rate=0.01, eps=1e-4, max_iterations=1000, anneal_learning_rate=None\n",
    "):\n",
    "    i = 0\n",
    "    x_old, x_new = 0, 2\n",
    "    # будем сохранять историю значений x и y\n",
    "    x_list, y_list = [x_old], [func(x_old)]\n",
    "    if not anneal_learning_rate:\n",
    "        anneal_learning_rate = lambda lr, step: lr\n",
    "\n",
    "    # TODO:\n",
    "    # Your code here\n",
    "    # --------------\n",
    "\n",
    "    # --------------\n",
    "    print(\"Найденный локальный минимум:\", x_new)\n",
    "    print(\"Количество шагов:\", len(x_list))\n",
    "    # Визуализируем сходимость\n",
    "    plt.figure(figsize=[6, 4])\n",
    "    plt.ylim([-3, 8])\n",
    "    plt.scatter(x_list, y_list, c=\"r\", edgecolors=\"k\")\n",
    "    plt.plot(x_list, y_list, c=\"r\")\n",
    "    plt.plot(x, func(x), c=\"b\")\n",
    "    plt.title(\"Descent trajectory\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBakKAc4KlZ8"
   },
   "source": [
    "Попробуем различные `learning_rate` и посмотрим на поведение оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBe4cH6vKlZ9",
    "outputId": "51c73140-ba1b-4e3f-b5f8-5391f1993cdf"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6qHwvrQKlaA"
   },
   "source": [
    "Слишком мало, будем очень долго идти к локальному минимуму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fJFR4SlKlaB",
    "outputId": "26d039e0-65cf-43e4-d1fe-0601dd06205b"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyeqRTitKlaF"
   },
   "source": [
    "Уже лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEX-iPPJKlaF",
    "outputId": "6c69720b-77bf-419a-dc9c-802540487e42"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Xz1B6hyKlaI",
    "outputId": "30e17323-25a8-464f-b050-8a5700f85c05"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTTbzvS0KlaM"
   },
   "source": [
    "Ууупс, получили Overflow. Значит learning rate слишком большой. Хотя большой learning rate опасен возможностью overflow у него есть ряд преимуществ. Чем больше темп обучения, тем большие расстояния мы преодолеваем за один шаг и тем выше вероятность быстрее найти хорошее пространство локальных минимумов.\n",
    "\n",
    "Хорошая стратегия — начинать с достаточно большого шага (чтобы хорошо попутешествовать по функции), а потом постепенно его уменьшать, чтобы стабилизировать процесс обучения в каком-то локальном минимуме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itCkyBdaKlaN"
   },
   "outputs": [],
   "source": [
    "find_minimum_first_order(0.6, anneal_learning_rate=lambda lr, step: 0.3 * lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSMWbov7ZrSQ"
   },
   "source": [
    "## Изучаем разные методы оптимизации\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "SGD - тот же самый gradient descent, что мы рассматривали ранее, но подсчёт градиентов производится не по всему множеству данных, а по отдельно взятому обьекту выборки. Очевидно, такая оптимизация будет очень шумной, что усложнит обучение модели. Поэтому обычно используют MiniBatch-SGD, где вместо одного сэмпла мы считаем градиент по $k$ обьектам. У такого подхода ниже дисперсия в сравнении с обычным SGD, что приводит к более стабильному процессу оптимизации, но контролируя $k$ мы можем контролировать используемую память.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "w &=& w - \\eta \\times g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "### Stochastic Gradient Descent with Momentum\n",
    "Попытаемся добавить в SGD эффект инерции. Теперь, вместо того чтобы двигаться строго в направлении градиента в каждой точке, мы стараемся продолжить движение в том же направлении, в котором двигались ранее. То есть у нашей точки, которая спускается по многомерной поверхности, появляется импульс (momentum), который контролируется при помощи параметра $\\alpha$. Он определяет какую часть прошлого градиента мы хотим использовать на текущем шаге.\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g_{t} &=& \\alpha g_{t-1} + \\eta \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "w &=& w - \\eta \\times g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "![Momentum](static/sgd_momentum.png)\n",
    "\n",
    "### Адаптивные варианты градиентного спуска\n",
    "Во всех предыдущих алгоритмах у нас был фиксированный learning rate. Теперь рассмотрим алгоритмы, которые подстраивают learning rate в зависимости от текущего процесса обучения. Они называются адаптивными вариантами градиентного спуска.\n",
    "\n",
    "Адаптивные варианты градиентного спуска подстраивают темп обучения таким образом, чтобы делать разные обновления для разных параметров. Например, может так сложиться, что некоторые веса близки к своим локальным минимумам, тогда по этим координатам нужно двигаться медленнее, а другие веса гораздо дальше от оптимума, значит их можно менять бОльшими шагами. Подобные методы часты приводят к более устойчивой модели и сходятся гораздо быстрее.\n",
    "\n",
    "#### Adagrad\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "s &=& s + diag(gg^{T}) \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{s+eps}} \\odot g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "Теперь нам не нужно сильно волноваться о правильном подборе $\\eta$, так как $s$ контролирует скорость обучения для каждого параметра.\n",
    "\n",
    "#### RMSprop\n",
    "У Adagrad есть сильный минус. $s$ - всегда положительна и постоянно растёт во время обучения, что приводит к ситуации, где learning rate становится слишком маленький, и мы перестаём учиться. RMSprop решает эту проблему при помощи экспоненциального сглаживания:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "s &=& \\rho s + (1 - \\rho) diag(gg^{T}) \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{s+eps}} \\odot g\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "#### Adam\n",
    "Добавим не только моменты второго порядка, но и первого при обновлении параметров:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "m &=& \\beta_1 m + (1 - \\beta_1) g \\\\\n",
    "v &=& \\beta_2 v + (1 - \\beta_2) diag(gg^{T}) \\\\\n",
    "\\hat{m} &=& \\frac{m}{1 - \\beta_1^{t}} \\\\\n",
    "\\hat{v} &=& \\frac{v}{1 - \\beta_2^{t}} \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{\\hat{v} + \\epsilon}} \\odot \\hat{m}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "#### Схема\n",
    "![Sheme](static/gd_scheme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeCXawXsKlaX"
   },
   "source": [
    "### Работаем с PyTorch Optimizer\n",
    "\n",
    "Очевидно, что для своих нейронных сетей не нужно каждый раз писать свой алгоритм и за вас уже сделаны все самые популярные методы. Их можно найти в **torch.optim** или по [ссылке](https://pytorch.org/docs/stable/optim.html#algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oraXo9DKlaX"
   },
   "outputs": [],
   "source": [
    "[elem for elem in dir(torch.optim) if not elem.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xsq3M5VKlaa"
   },
   "source": [
    "Основные методы PyTorch Optimizer:\n",
    "* __step__ - обновление весов модели\n",
    "* __zero_grad__ - занулить веса модели (по умолчанию градиенты в PyTorch аккумулируются) ~ `for each param in params: param.grad = None`\n",
    "* __state_dict__ - получить текущее состояние Optimizer. Для адаптивных методов тут будут храниться аккумулированные квадраты градиентов\n",
    "\n",
    "\n",
    "### Как создать инстанс PyTorch Optimizer?\n",
    "\n",
    "Для того чтобы создать инстанс оптимизатора, достаточно передать ему параметры модели (их можно получить при помощи функции `parameters()`) и гиперпараметры для метода оптимизации.\n",
    "\n",
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLLI3GbM89kb"
   },
   "outputs": [],
   "source": [
    "?torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDgqvgVJKlaa",
    "outputId": "0e41c5d8-6415-4560-86d8-c7f9b9645685"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(1, 1)\n",
    "list(model.named_parameters()), torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rpMKRptKlac"
   },
   "source": [
    "Или же вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6mSL4-CKlad",
    "outputId": "57294f79-f719-474d-8e35-550aee425e94"
   },
   "outputs": [],
   "source": [
    "# Зададим PyTorch модули в качестве словаря\n",
    "model = torch.nn.ModuleDict(\n",
    "    {\"linear_1\": torch.nn.Linear(1, 1), \"linear_2\": torch.nn.Linear(2, 2)}\n",
    ")\n",
    "torch.optim.SGD(\n",
    "    [\n",
    "        {\"params\": model[\"linear_1\"].parameters(), \"lr\": 0.3},\n",
    "        {\"params\": model[\"linear_2\"].parameters()},\n",
    "    ],\n",
    "    lr=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jyw8oX6vpaO9"
   },
   "source": [
    "Последнее очень полезно, например, для transfer learning, когда мы хотим, чтобы предобученная модель тренировалась с другим learning rate.\n",
    "\n",
    "**Важный момент:** даже если у вас есть методы с адаптивным градиентом спуском, полностью забывать о настройке learning rate не стоит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работаем с PyTorch Scheduler\n",
    "\n",
    "В начале семинара мы уменьшили количество шагов до сходимости следующим образом: начали с достаточно большого шага, а потом постепенно его уменьшили, чтобы стабилизировать процесс обучения в минимуме. Оказывается есть много способов менять оптимизацию таким образом. Они называются Schedulers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ghk6fqbIqX_G",
    "outputId": "452ff276-4b52-494b-8d96-e1d9296be5e6"
   },
   "outputs": [],
   "source": [
    "[elem for elem in dir(torch.optim.lr_scheduler) if not elem.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00r2hf3HvUAR"
   },
   "source": [
    "Основные методы PyTorch Scheduler:\n",
    "* __step__ - обновление размера шага. *Обычно вызывается **1 раз за эпоху**, а не каждый шаг оптимизатора.*\n",
    "* __state_dict__ - получить текущее состояние Scheduler: текущий LR, количество пройденных шагов и дополнительные параметры.\n",
    "\n",
    "\n",
    "### Как создать инстанс PyTorch Scheduler?\n",
    "\n",
    "Достаточно передать `optimizer` и гиперпараметры для метода.\n",
    "\n",
    "Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKZwrKBpwmsy"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler_func = lambda epoch: 0.65**epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, scheduler_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xl6QuDjjrZmG"
   },
   "source": [
    "Сделаем пару небольших функций для отрисовки изменения шага обучения на разных шедулерах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zeYr14lrQ_j"
   },
   "outputs": [],
   "source": [
    "def get_simple_model_optimizer():\n",
    "    simple_model = torch.nn.Linear(2, 1)\n",
    "    simple_optimizer = torch.optim.SGD(model.parameters(), lr=100)\n",
    "    return simple_model, simple_optimizer\n",
    "\n",
    "\n",
    "def draw_learning_rate_curve(optimizer, scheduler):\n",
    "    lrs = []\n",
    "    for i in range(100):\n",
    "        optimizer.step()\n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        scheduler.step()\n",
    "    plt.grid()\n",
    "    plt.plot(range(100), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJJQ9HEQtpqY"
   },
   "source": [
    "### Примеры различных шедулеров в **PyTorch**\n",
    "\n",
    "#### Lambda LR\n",
    "Умножает шаг на значение данной ему функции: $lr_{epoch} = lr_{initial} * Lambda(epoch)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZS4XOR8tK_E",
    "outputId": "762e72fb-8c24-4004-acad-26faa14f4da0"
   },
   "outputs": [],
   "source": [
    "model, optimizer = get_simple_model_optimizer()\n",
    "lambda_func = lambda epoch: 0.95**epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "draw_learning_rate_curve(optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8PuQb8fuIno"
   },
   "source": [
    "#### StepLR\n",
    "Каждые `step_size` эпох уменьшает LR в `gamma` раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNPhic8utbVb",
    "outputId": "70c634c1-82be-4f80-ff0f-84255099ed43"
   },
   "outputs": [],
   "source": [
    "model, optimizer = get_simple_model_optimizer()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "draw_learning_rate_curve(optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3Ztt5AoyQCA"
   },
   "source": [
    "#### CosineAnnealingLR\n",
    "\n",
    "Важно понимать, что LR имеет смысл не только снижать, но иногда еще и делать цикличным. Формула тут несколько сложнее, оставим ее для интересующихся)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPBv2i47yPOe",
    "outputId": "49b1fab9-aadb-4752-e494-c7dc1cfc9992"
   },
   "outputs": [],
   "source": [
    "model, optimizer = get_simple_model_optimizer()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "draw_learning_rate_curve(optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YmhZSXV4EBp"
   },
   "source": [
    "## PyTorch VS PyTorch Lightning\n",
    "\n",
    "**PyTorch Lightning** это фреймворк для организованной работы с **PyTorch**. В нем упрощена работа по:\n",
    "- Написанию тренировочного цикла\n",
    "- Написанию датасетов\n",
    "- Использованию gpu/tpu/ipu/hpu и тд\n",
    "- Переводу моделей в формат ONNX\n",
    "- И многому другому\n",
    "\n",
    "Фреймворк призван оставить юзеру возможность конфигурировать параметры и проводить эксперименты, а остальное он возьмет на себя. Давайте сравним код на **PyTorch** без и с использованием **Lightning** на примере несложной нейросети на датасете FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# крутая библиотека с кучей метрик \"из коробки\"\n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные (общее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHAHgGdeKlau"
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "fashion_mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\", download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    fashion_mnist_train, batch_size=128, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "fashion_mnist_val = torchvision.datasets.FashionMNIST(\n",
    "    \"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "val_dataloader = DataLoader(fashion_mnist_val, batch_size=128, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr1MKTjBKlaw"
   },
   "outputs": [],
   "source": [
    "idx_to_label = defaultdict(\n",
    "    None,\n",
    "    {\n",
    "        0: \"T-shirt/Top\",\n",
    "        1: \"Trouser\",\n",
    "        2: \"Pullover\",\n",
    "        3: \"Dress\",\n",
    "        4: \"Coat\",\n",
    "        5: \"Sandal\",\n",
    "        6: \"Shirt\",\n",
    "        7: \"Sneaker\",\n",
    "        8: \"Bag\",\n",
    "        9: \"Ankle Boot\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQfTpcB05ZcB",
    "outputId": "860eecc7-21ce-46df-acf0-5f105163f0f5"
   },
   "outputs": [],
   "source": [
    "### pictures are normalized\n",
    "for batch in val_dataloader:\n",
    "    # batch_size is 128\n",
    "    images, class_nums = batch\n",
    "    print(idx_to_label[int(class_nums[0])])\n",
    "    plt.imshow(images[0].squeeze())\n",
    "    plt.show()\n",
    "    print(idx_to_label[int(class_nums[127])])\n",
    "    plt.imshow(images[127].squeeze())\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6Mf1W49f2Fv"
   },
   "source": [
    "### Модель (общее)\n",
    "\n",
    "Создайте класс модели по следующей схеме:\n",
    "\n",
    "1. BatchNorm\n",
    "2. Conv(out=32, kernel=3) -> ReLu -> MaxPool(kernel=2)\n",
    "3. BatchNorm\n",
    "4. Conv(out=64, kernel=3) -> ReLu -> MaxPool(kernel=2)\n",
    "5. Flatten\n",
    "6. Linear(out=128)\n",
    "7. ReLu\n",
    "8. Dropout\n",
    "9. Linear(out=64)\n",
    "10. ReLu\n",
    "11. Linear(out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkHmFRSkKlay"
   },
   "outputs": [],
   "source": [
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self, dropout=0.4):\n",
    "        super().__init__()\n",
    "        # TODO:\n",
    "        # Your code here:\n",
    "        # --------------\n",
    "\n",
    "        # --------------\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        self.targets = torch.Tensor()\n",
    "        self.preds = torch.Tensor()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # runs the neural network\n",
    "        # TODO:\n",
    "        # Your code here\n",
    "        # --------------\n",
    "\n",
    "        # --------------\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._forward(images)\n",
    "\n",
    "        # get accuracy score and save it to self.accuracy\n",
    "        if target is not None:\n",
    "            loss = self.loss_func(output, target)\n",
    "\n",
    "            self.targets = torch.cat((self.targets, target.cpu()), 0)\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.preds = torch.cat((self.preds, pred.cpu()), 0)\n",
    "            self.accuracy = accuracy(self.preds.long(), self.targets.long())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # return accuracy by all values till now\n",
    "        if reset:\n",
    "            self.targets = torch.Tensor()\n",
    "            self.preds = torch.Tensor()\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRuVz6TXFANc"
   },
   "source": [
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xmAPz91FAZb"
   },
   "outputs": [],
   "source": [
    "LossInfo = namedtuple(\n",
    "    \"LossInfo\", [\"full_train_losses\", \"train_epoch_losses\", \"eval_epoch_losses\"]\n",
    ")\n",
    "EPOCHS = 10\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkLsRtR2-U6d"
   },
   "source": [
    "### Тренировочные циклы (PyTorch)\n",
    "\n",
    "Здесь нам надо будет объявить функции `train_epoch`, `validate`, `fit`.\n",
    "Структура, напомним, выглядит, в упрощенном виде, так:\n",
    "```\n",
    "def train_epoch():\n",
    "    for batch in train_loader:\n",
    "        train_model_on_batch()\n",
    "def validate():\n",
    "    for batch in val_loader:\n",
    "        validate_model_on_batch()\n",
    "def fit():\n",
    "    for epoch in range(1, num_epochs):\n",
    "        train_epoch()\n",
    "        validate()\n",
    "```\n",
    "Но на деле это все намного сложнее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EKZRgiLPKlaz"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    return_losses=False,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_losses = []\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for batch in data_loader:\n",
    "            # move Batch to GPU\n",
    "            batch = [x.to(device=device) for x in batch]\n",
    "            loss = model(*batch)\n",
    "            # update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # update description for tqdm\n",
    "            accuracy = model.get_accuracy()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            all_losses.append(loss.detach().item())\n",
    "    acc = model.get_accuracy(reset=True)\n",
    "    metrics = {\"loss\": total_loss / num_batches, \"accuracy\": acc}\n",
    "    if return_losses:\n",
    "        return metrics, all_losses\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def validate(model, data_loader, device=\"cuda:0\"):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for batch in data_loader:\n",
    "            batch = [x.to(device=device) for x in batch]\n",
    "            loss = model(*batch)\n",
    "            accuracy = model.get_accuracy()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    acc = model.get_accuracy(reset=True)\n",
    "    metrics = {\"loss\": total_loss / num_batches, \"accuracy\": acc}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmOlOzBnKla2"
   },
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model,\n",
    "    epochs,\n",
    "    train_data_loader,\n",
    "    validation_data_loader,\n",
    "    optimizer,\n",
    "    scheduler=None,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    all_train_losses = []\n",
    "    epoch_train_losses = []\n",
    "    epoch_eval_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        # construct iterators\n",
    "        train_iterator = iter(train_data_loader)\n",
    "        validation_iterator = iter(validation_data_loader)\n",
    "        # train step\n",
    "        print(f\"Train Epoch: {epoch}\")\n",
    "        train_metrics, one_epoch_train_losses = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_iterator,\n",
    "            optimizer=optimizer,\n",
    "            return_losses=True,\n",
    "            device=device,\n",
    "        )\n",
    "        # save train losses\n",
    "        all_train_losses.extend(one_epoch_train_losses)\n",
    "        epoch_train_losses.append(train_metrics[\"loss\"])\n",
    "        # eval step\n",
    "        print(f\"Validation Epoch: {epoch}\")\n",
    "        with torch.no_grad():\n",
    "            validation_metrics = validate(\n",
    "                model=model, data_loader=validation_iterator, device=device\n",
    "            )\n",
    "        # save eval losses\n",
    "        epoch_eval_losses.append(validation_metrics[\"loss\"])\n",
    "        # scheduler step\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "    return LossInfo(all_train_losses, epoch_train_losses, epoch_eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SanI3hS6JQrL",
    "outputId": "71e443c6-2d1c-4145-94e4-80f0219ad41f"
   },
   "outputs": [],
   "source": [
    "# проверим, что всё работает (±1 минута на гпу):\n",
    "model = SimpleNet().to(device)\n",
    "_ = fit(\n",
    "    model=model,\n",
    "    epochs=1,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=val_dataloader,\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=LR),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b0XCReZ4w0W"
   },
   "source": [
    "### Тренировочные циклы (Lightning)\n",
    "\n",
    "Здесь будет немного другая структура.\n",
    "\n",
    "1) Создается 1 класс отнаследованный от `pl.LightningModule`. В нем описывается сама модель, необходимые функции тренировочного и валидационного шага.\n",
    "\n",
    "2) Создается объект класса `pl.Trainer` с параметрами (напр. номер гпу, кол-во эпох, град. клиппинг и так далее) дока [тут](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer) или [тут](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html?highlight=trainer#trainer-flags).\n",
    "\n",
    "3) Вызывается `trainer.fit(model, train_loader, val_loader)`.\n",
    "\n",
    "\n",
    "```\n",
    "class MyModule(pl.LightningModule):\n",
    "    def init():\n",
    "        init_model()\n",
    "    def forward():\n",
    "        forward_model()\n",
    "    def training_step():\n",
    "        make_1_training_step()\n",
    "    def validation_step():\n",
    "        make_1_validation_step()\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=10)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "```\n",
    "Поскольку у нас уже есть модель `SimpleNet`, то исправлять нам много не надо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqO3RxM24urH"
   },
   "outputs": [],
   "source": [
    "# 1) create a LightningModule\n",
    "class SimpleModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        images, target = train_batch\n",
    "        loss = self.model(images, target)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, prog_bar=True\n",
    "        )  # сохраняет логи в папку, но можно несложно добавить wandb\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        images, target = val_batch\n",
    "        loss = self.model(images, target)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619,
     "referenced_widgets": [
      "77f193d9a291486eaef5632783d70c6f",
      "0dd132cfd7c948e890005903be333946",
      "6eddef9ffdaa46929900fadb15f4e7f7",
      "9eb1fbedba294c21b9042a0a7956be58",
      "2457572529ac4ef0bf76edbed0cde40b",
      "744a7cd8d694408f9b040a49ffb8c694",
      "6586865f10ee4577b5257ec0a4bb49a3",
      "15100a91b69f4b19bf41c5b02923ce63",
      "3ae0034beab24c77ab7b2260db371f3e",
      "e1c1b0c7029241a7870f39626be926d0",
      "306b2b07de49455eadd8ba0561844d19",
      "99223ebdaaf3421c88fb18d48e1c4a03",
      "300daed98fdb4ea8af1e8af7de0ea6ff",
      "60652e3d1510478c9c6ef3fc7060bac6",
      "546e464c00cb4b0ba30acbe5a0fac5bf",
      "c590a019380a48c7847626c3ee85c8b4",
      "71a02bb021d8465c8486418804b046c9",
      "5aea5ac1674a4c0481047d3fe98e3214",
      "bd3c24662e9f4486a19cf62e082c3d18",
      "9295c27b0f9d4532bc3bfb687672e232",
      "f24dc9fbeb904ec1854117ac78ce37c5",
      "bd145f6605854fcc8c0deb185199a665",
      "c632971657794b51b66436fc58012d8d",
      "389bce6eee014c37bea40b4eb3b42901",
      "d08aef71277445c6848a7ce875610797",
      "e2edebab198b4dc59f5ecdad516ccdec",
      "2d5124d213b14f2ab166854727329699",
      "9a51ff086a7b480984d11da1746220d6",
      "62786cf112dc427b8ad10c25a7b6d452",
      "900bac62ecbb48b8b169b3371868f388",
      "3dae5396844640828edda0bc0279db85",
      "7e05dbdf17584419954aa9577acd2e88",
      "7da6e22fbb7b4afb8fe9ed4b673f876e"
     ]
    },
    "id": "Ihtd_7Qv-rVA",
    "outputId": "2f92ca56-a925-4fb2-820d-a199308394b8"
   },
   "outputs": [],
   "source": [
    "# 2) create module\n",
    "\n",
    "model = SimpleNet().to(device)\n",
    "module = SimpleModule(model, learning_rate=LR)\n",
    "\n",
    "# 3) create Trainer and train (±30 seconds on gpu)\n",
    "trainer = pl.Trainer(accelerator=\"cpu\", max_epochs=1)\n",
    "trainer.fit(module, train_dataloader, val_dataloader)\n",
    "\n",
    "# 3.5) we can also find best learning rate like this: https://pytorch-lightning.readthedocs.io/en/1.4.5/advanced/lr_finder.html\n",
    "# trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=2, auto_lr_find=True)\n",
    "# trainer.tune(module, train_dataloader, eval_dataloader)\n",
    "# trainer.fit(module, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XThjhAsA-pxW"
   },
   "source": [
    "Обратите внимание **насколько** поведение `trainer.fit()` сильно похоже на написанную нами ранее функцию `fit()`\n",
    "\n",
    "\n",
    "Заметьте также, что на Lightning мы:\n",
    "1.   Не описывали тренировочный цикл ни по эпохам, ни по батчам\n",
    "2.   Не рисковали забыть zero_grad, .backward()\n",
    "3.   Не переносили ни модель, ни данные на GPU\n",
    "4.   Получили всякие приколы типа auto_lr_find \n",
    "5.   Сохранили возможность использования многих тонкостей **PyTorch** типа [schedulers](https://pytorch-lightning.readthedocs.io/en/stable/common/optimization.html), логирование через [wandb](https://docs.wandb.ai/guides/integrations/lightning) и так далее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTnyRAFB8266"
   },
   "source": [
    "## Сравнением работу разных оптимизаторов\n",
    "\n",
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xe-wjJqEXzOY",
    "outputId": "daa5d491-c1dd-4bd2-dee6-7fca70c0b776"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device=device)\n",
    "sgd_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=val_dataloader,\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=LR),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNsHDEOuX_I8"
   },
   "source": [
    "### SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WETr80TZXo1Z",
    "outputId": "3a0cdc44-851c-453e-c8cc-07a24288477a"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device=device)\n",
    "sgd_momentum_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=val_dataloader,\n",
    "    optimizer=torch.optim.SGD(model.parameters(), momentum=0.9, lr=LR),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ra4g-7ztvBC3"
   },
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pP7tS4gsu_7o",
    "outputId": "72c29f91-e7e2-449b-eeaa-5246580f1e3c"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device=device)\n",
    "rmsprop_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=val_dataloader,\n",
    "    optimizer=torch.optim.RMSprop(model.parameters(), lr=LR),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1-4TFPaYNFP"
   },
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgDi8etcYKxL",
    "outputId": "197551f6-35fb-454e-ff74-d3b0a897b634"
   },
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device=device)\n",
    "adam_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=val_dataloader,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LR),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-EKFButKxn6"
   },
   "source": [
    "### Adam + Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device=device)\n",
    "lambda_func = lambda epoch: 0.975**epoch\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "adam_scheduler_loss_info = fit(\n",
    "    model=model,\n",
    "    epochs=EPOCHS,\n",
    "    train_data_loader=train_dataloader,\n",
    "    validation_data_loader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидации получается значение несколько лучше, чем у просто Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графики падения лосса при разных способах оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * 10),\n",
    "    sgd_loss_info.full_train_losses,\n",
    "    label=\"SGD\",\n",
    "    c=\"grey\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * 10),\n",
    "    sgd_momentum_loss_info.full_train_losses,\n",
    "    label=\"SGD Momentum\",\n",
    "    c=\"blue\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * 10),\n",
    "    rmsprop_loss_info.full_train_losses,\n",
    "    label=\"RMSProp\",\n",
    "    c=\"green\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * 10),\n",
    "    adam_loss_info.full_train_losses,\n",
    "    label=\"Adam\",\n",
    "    c=\"red\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(len(train_dataloader) * 10),\n",
    "    adam_scheduler_loss_info.full_train_losses,\n",
    "    label=\"Adam+Scheduler\",\n",
    "    c=\"black\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(10), sgd_loss_info.eval_epoch_losses, label=\"SGD\", c=\"grey\")\n",
    "plt.plot(\n",
    "    np.arange(10),\n",
    "    sgd_momentum_loss_info.eval_epoch_losses,\n",
    "    label=\"SGD Momentum\",\n",
    "    c=\"blue\",\n",
    ")\n",
    "plt.plot(np.arange(10), rmsprop_loss_info.eval_epoch_losses, label=\"RMSprop\", c=\"green\")\n",
    "plt.plot(np.arange(10), adam_loss_info.eval_epoch_losses, label=\"Adam\", c=\"red\")\n",
    "plt.plot(\n",
    "    np.arange(10),\n",
    "    adam_scheduler_loss_info.eval_epoch_losses,\n",
    "    label=\"Adam+Scheduler\",\n",
    "    c=\"black\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kD68Ub9hKlZy",
    "ZeCXawXsKlaX",
    "bWG6WICUKlaa",
    "mO_Y_-HUo8zL",
    "1Icmb2vUwppF",
    "BQWRUIQ25Mci",
    "Q6Mf1W49f2Fv",
    "zRuVz6TXFANc",
    "MkLsRtR2-U6d",
    "VTnyRAFB8266",
    "ErRCAeIeEePe"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dd132cfd7c948e890005903be333946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744a7cd8d694408f9b040a49ffb8c694",
      "placeholder": "​",
      "style": "IPY_MODEL_6586865f10ee4577b5257ec0a4bb49a3",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "15100a91b69f4b19bf41c5b02923ce63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2457572529ac4ef0bf76edbed0cde40b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "2d5124d213b14f2ab166854727329699": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": "100%"
     }
    },
    "300daed98fdb4ea8af1e8af7de0ea6ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71a02bb021d8465c8486418804b046c9",
      "placeholder": "​",
      "style": "IPY_MODEL_5aea5ac1674a4c0481047d3fe98e3214",
      "value": "Epoch 1:  33%"
     }
    },
    "306b2b07de49455eadd8ba0561844d19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "389bce6eee014c37bea40b4eb3b42901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a51ff086a7b480984d11da1746220d6",
      "placeholder": "​",
      "style": "IPY_MODEL_62786cf112dc427b8ad10c25a7b6d452",
      "value": "Validation DataLoader 0: 100%"
     }
    },
    "3ae0034beab24c77ab7b2260db371f3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3dae5396844640828edda0bc0279db85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "546e464c00cb4b0ba30acbe5a0fac5bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f24dc9fbeb904ec1854117ac78ce37c5",
      "placeholder": "​",
      "style": "IPY_MODEL_bd145f6605854fcc8c0deb185199a665",
      "value": " 180/548 [00:25&lt;00:52,  7.04it/s, loss=0.272, v_num=6, train_loss=0.282, val_loss=0.286]"
     }
    },
    "5aea5ac1674a4c0481047d3fe98e3214": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60652e3d1510478c9c6ef3fc7060bac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd3c24662e9f4486a19cf62e082c3d18",
      "max": 548,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9295c27b0f9d4532bc3bfb687672e232",
      "value": 180
     }
    },
    "62786cf112dc427b8ad10c25a7b6d452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6586865f10ee4577b5257ec0a4bb49a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6eddef9ffdaa46929900fadb15f4e7f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15100a91b69f4b19bf41c5b02923ce63",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ae0034beab24c77ab7b2260db371f3e",
      "value": 2
     }
    },
    "71a02bb021d8465c8486418804b046c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "744a7cd8d694408f9b040a49ffb8c694": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77f193d9a291486eaef5632783d70c6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dd132cfd7c948e890005903be333946",
       "IPY_MODEL_6eddef9ffdaa46929900fadb15f4e7f7",
       "IPY_MODEL_9eb1fbedba294c21b9042a0a7956be58"
      ],
      "layout": "IPY_MODEL_2457572529ac4ef0bf76edbed0cde40b"
     }
    },
    "7da6e22fbb7b4afb8fe9ed4b673f876e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e05dbdf17584419954aa9577acd2e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "900bac62ecbb48b8b169b3371868f388": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9295c27b0f9d4532bc3bfb687672e232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99223ebdaaf3421c88fb18d48e1c4a03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_300daed98fdb4ea8af1e8af7de0ea6ff",
       "IPY_MODEL_60652e3d1510478c9c6ef3fc7060bac6",
       "IPY_MODEL_546e464c00cb4b0ba30acbe5a0fac5bf"
      ],
      "layout": "IPY_MODEL_c590a019380a48c7847626c3ee85c8b4"
     }
    },
    "9a51ff086a7b480984d11da1746220d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eb1fbedba294c21b9042a0a7956be58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1c1b0c7029241a7870f39626be926d0",
      "placeholder": "​",
      "style": "IPY_MODEL_306b2b07de49455eadd8ba0561844d19",
      "value": " 2/2 [00:00&lt;00:00,  8.85it/s]"
     }
    },
    "bd145f6605854fcc8c0deb185199a665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd3c24662e9f4486a19cf62e082c3d18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c590a019380a48c7847626c3ee85c8b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "c632971657794b51b66436fc58012d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_389bce6eee014c37bea40b4eb3b42901",
       "IPY_MODEL_d08aef71277445c6848a7ce875610797",
       "IPY_MODEL_e2edebab198b4dc59f5ecdad516ccdec"
      ],
      "layout": "IPY_MODEL_2d5124d213b14f2ab166854727329699"
     }
    },
    "d08aef71277445c6848a7ce875610797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_900bac62ecbb48b8b169b3371868f388",
      "max": 79,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dae5396844640828edda0bc0279db85",
      "value": 79
     }
    },
    "e1c1b0c7029241a7870f39626be926d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2edebab198b4dc59f5ecdad516ccdec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e05dbdf17584419954aa9577acd2e88",
      "placeholder": "​",
      "style": "IPY_MODEL_7da6e22fbb7b4afb8fe9ed4b673f876e",
      "value": " 79/79 [00:09&lt;00:00,  8.23it/s]"
     }
    },
    "f24dc9fbeb904ec1854117ac78ce37c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
